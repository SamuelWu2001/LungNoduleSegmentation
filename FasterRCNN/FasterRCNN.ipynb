{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2607711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:08:24.889688Z",
     "iopub.status.busy": "2023-06-04T04:08:24.889258Z",
     "iopub.status.idle": "2023-06-04T04:08:28.072288Z",
     "shell.execute_reply": "2023-06-04T04:08:28.071359Z"
    },
    "id": "vNOZbkjDREXX",
    "papermill": {
     "duration": 3.193607,
     "end_time": "2023-06-04T04:08:28.074770",
     "exception": false,
     "start_time": "2023-06-04T04:08:24.881163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import pickle\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4be620b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:08:28.087868Z",
     "iopub.status.busy": "2023-06-04T04:08:28.087367Z",
     "iopub.status.idle": "2023-06-04T04:08:28.147644Z",
     "shell.execute_reply": "2023-06-04T04:08:28.146533Z"
    },
    "id": "bfYa8Bvg7v0f",
    "outputId": "18ff944a-affb-4550-b0fc-a5e0a645f956",
    "papermill": {
     "duration": 0.069013,
     "end_time": "2023-06-04T04:08:28.149638",
     "exception": false,
     "start_time": "2023-06-04T04:08:28.080625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \n",
    "print(\"Use device:\",device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da5348d5",
   "metadata": {},
   "source": [
    "# Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27295390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:08:28.163709Z",
     "iopub.status.busy": "2023-06-04T04:08:28.163081Z",
     "iopub.status.idle": "2023-06-04T04:08:28.168319Z",
     "shell.execute_reply": "2023-06-04T04:08:28.167438Z"
    },
    "papermill": {
     "duration": 0.01492,
     "end_time": "2023-06-04T04:08:28.170324",
     "exception": false,
     "start_time": "2023-06-04T04:08:28.155404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "lr = 0.001\n",
    "pretrain = False\n",
    "mode = 'train'\n",
    "epoch = 40\n",
    "rpn_pos_per_batch = []\n",
    "rpn_neg_per_batch = []\n",
    "val_rpn_pos_per_batch = []\n",
    "val_rpn_neg_per_batch = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d50f1f",
   "metadata": {
    "id": "O-5x61Vu5ynf",
    "papermill": {
     "duration": 0.005391,
     "end_time": "2023-06-04T04:08:28.181180",
     "exception": false,
     "start_time": "2023-06-04T04:08:28.175789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b280efc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:08:28.194031Z",
     "iopub.status.busy": "2023-06-04T04:08:28.193293Z",
     "iopub.status.idle": "2023-06-04T04:09:27.393062Z",
     "shell.execute_reply": "2023-06-04T04:09:27.390610Z"
    },
    "id": "0pbpMDEP5x2y",
    "outputId": "58ba42f5-ae6b-427a-fe3d-95e372ca0eda",
    "papermill": {
     "duration": 59.20838,
     "end_time": "2023-06-04T04:09:27.395154",
     "exception": false,
     "start_time": "2023-06-04T04:08:28.186774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3395/3395 [00:59<00:00, 57.42it/s]\n"
     ]
    }
   ],
   "source": [
    "meta = pd.read_csv('/kaggle/input/lidcidri-250-500/data/Meta/meta_info.csv')\n",
    "\n",
    "# test 1-30 valid 31-40 test 41-50\n",
    "train_img = []\n",
    "valid_img = []\n",
    "test_img = []\n",
    "train_bbox = []\n",
    "valid_bbox = []\n",
    "test_bbox = []\n",
    "train_label = []\n",
    "valid_label = []\n",
    "test_label = []\n",
    "\n",
    "\n",
    "# bbox_list = np.load('/content/drive/MyDrive/fasterRCNN/data/bbox.pkl')\n",
    "with open('/kaggle/input/lidcidri-250-500/data/bbox.pkl', \"rb\") as file:\n",
    "    bbox_list = pickle.load(file)\n",
    "\n",
    "# for i in range(len(bbox_list)):\n",
    "#   for j in range(len(bbox_list[i])):\n",
    "#     bbox_list[i][j][0] = bbox_list[i][j][0]*600/512\n",
    "#     bbox_list[i][j][1] = bbox_list[i][j][1]*600/512\n",
    "#     bbox_list[i][j][2] = bbox_list[i][j][2]*600/512\n",
    "#     bbox_list[i][j][3] = bbox_list[i][j][3]*600/512\n",
    "\n",
    "for i in tqdm(range(len(meta.index))):\n",
    "    if meta.iloc[i]['is_clean'] == False:\n",
    "        img = np.load('/kaggle/input/lidcidri-250-500/data/Image/LIDC-IDRI-' + meta.iloc[i]['original_image'][:4] + '/' + meta.iloc[i]['original_image'] + '.npy') \n",
    "    else :\n",
    "        img = np.load('/kaggle/input/lidcidri-250-500/data/Clean/Image/LIDC-IDRI-' + meta.iloc[i]['original_image'][:4] + '/' + meta.iloc[i]['original_image'] + '.npy')\n",
    "    if img.shape[0] != 512 or img.shape[1] != 512:\n",
    "        print(img.shape, meta.iloc[i]['patient_id'])\n",
    "    img = np.clip(img, -1200,1200)\n",
    "    img = torch.Tensor(img)\n",
    "    img = img.to(torch.float32) \n",
    "    min_value = img.min()\n",
    "    max_value = img.max()    \n",
    "\n",
    "    # Shift the tensor to make all values positive\n",
    "    shifted_tensor = img - min_value   \n",
    "    # Normalize the tensor to the range [0, 1]\n",
    "    img = shifted_tensor / (max_value - min_value)\n",
    "\n",
    "    if meta.iloc[i]['patient_id'] <= 450: \n",
    "        train_img.append(img)\n",
    "        train_bbox.append(bbox_list[i])\n",
    "        if meta.iloc[i]['is_clean'] == False:\n",
    "            train_label.append(torch.ones(len(bbox_list[i])).type(torch.int64))\n",
    "        else:\n",
    "            train_label.append(torch.zeros(len(bbox_list[i])).type(torch.int64))\n",
    "    elif meta.iloc[i]['patient_id'] <= 475: \n",
    "        valid_img.append(img)\n",
    "        valid_bbox.append(bbox_list[i])\n",
    "        if meta.iloc[i]['is_clean'] == False:\n",
    "            valid_label.append(torch.ones(len(bbox_list[i])).type(torch.int64))\n",
    "        else:\n",
    "            valid_label.append(torch.zeros(len(bbox_list[i])).type(torch.int64))\n",
    "    else : \n",
    "        test_img.append(img)\n",
    "        test_bbox.append(bbox_list[i])\n",
    "        if meta.iloc[i]['is_clean'] == False:\n",
    "            test_label.append(torch.ones(len(bbox_list[i])).type(torch.int64))\n",
    "        else:\n",
    "            test_label.append(torch.zeros(len(bbox_list[i])).type(torch.int64))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee710b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:09:27.487137Z",
     "iopub.status.busy": "2023-06-04T04:09:27.486529Z",
     "iopub.status.idle": "2023-06-04T04:09:27.493939Z",
     "shell.execute_reply": "2023-06-04T04:09:27.493076Z"
    },
    "id": "qmfQwsOU4PoW",
    "outputId": "3096783e-0e11-4827-fcae-e3da6991f192",
    "papermill": {
     "duration": 0.054971,
     "end_time": "2023-06-04T04:09:27.496055",
     "exception": false,
     "start_time": "2023-06-04T04:09:27.441084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2564 408 422 2563 408 422 2565 408 422\n"
     ]
    }
   ],
   "source": [
    "print(len(train_img[:-1]), len(valid_img), len(test_img), len(train_bbox[:-2]), len(valid_bbox), len(test_bbox), len(train_label), len(valid_label), len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923ed38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:09:27.585441Z",
     "iopub.status.busy": "2023-06-04T04:09:27.584941Z",
     "iopub.status.idle": "2023-06-04T04:09:27.827954Z",
     "shell.execute_reply": "2023-06-04T04:09:27.826981Z"
    },
    "id": "jeglxwZn7rkc",
    "outputId": "15147723-b425-491c-f6a4-7b9da1c437ab",
    "papermill": {
     "duration": 0.291195,
     "end_time": "2023-06-04T04:09:27.830961",
     "exception": false,
     "start_time": "2023-06-04T04:09:27.539766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class FasterRCNNDataset(Dataset):\n",
    "    def __init__(self, image_list, bboxes_list, labels_list, transform=None):\n",
    "        self.image_list = image_list\n",
    "        self.bboxes_list = bboxes_list\n",
    "        self.labels_list = labels_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.image_list[idx]\n",
    "        bboxes = self.bboxes_list[idx]\n",
    "        labels = self.labels_list[idx]\n",
    "\n",
    "        image = torch.tensor(image)\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        bboxes = torch.tensor(bboxes)\n",
    "        labels = labels\n",
    "\n",
    "        return image, bboxes, labels\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    image_list = []\n",
    "    bboxes_list = []\n",
    "    labels_list = []\n",
    "    for item in batch:\n",
    "        image_list.append(item[0])\n",
    "        bboxes_list.append(item[1])\n",
    "        labels_list.append(item[2])\n",
    "\n",
    "    # Pad the lists of bounding boxes with -1\n",
    "    max_num_bboxes = max(len(bboxes) for bboxes in bboxes_list)\n",
    "    padded_bboxes_list = []\n",
    "    for bboxes in bboxes_list:\n",
    "        padded_bboxes = torch.cat((bboxes, torch.tensor([[-1, -1, -1, -1]]).expand((max_num_bboxes - len(bboxes)), -1)), dim=0)\n",
    "        padded_bboxes_list.append(padded_bboxes)\n",
    "\n",
    "    # Pad label\n",
    "    max_num_labels = max_num_bboxes\n",
    "    padded_labels_list = []\n",
    "    for labels in labels_list:\n",
    "        padded_labels = torch.cat((labels, torch.zeros(max_num_labels - len(labels)).type(torch.int64)), dim=0)\n",
    "        padded_labels_list.append(padded_labels)\n",
    "    # Convert images, bboxes, and labels to tensors\n",
    "    image_list = torch.stack(image_list)\n",
    "    padded_bboxes_list = torch.stack(padded_bboxes_list)\n",
    "    padded_labels_list = torch.stack(padded_labels_list)\n",
    "\n",
    "    return image_list, padded_bboxes_list, padded_labels_list\n",
    "\n",
    "# transform  = transforms.Resize([600,600]) \n",
    "train_dataset = FasterRCNNDataset(train_img, train_bbox, train_label)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "valid_dataset = FasterRCNNDataset(valid_img, valid_bbox, valid_label)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "valid_iou_dataloader = DataLoader(valid_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "test_dataset = FasterRCNNDataset(test_img, test_bbox, test_label)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "for images, bboxes, labels in train_dataloader:\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Bounding boxes shape:\", bboxes.shape)\n",
    "    print(\"Labels shape:\", labels.shape, labels)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e0800",
   "metadata": {
    "id": "KRO5QpJKx2cs",
    "papermill": {
     "duration": 0.043371,
     "end_time": "2023-06-04T04:09:27.918654",
     "exception": false,
     "start_time": "2023-06-04T04:09:27.875283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b9b8b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:09:28.007247Z",
     "iopub.status.busy": "2023-06-04T04:09:28.006953Z",
     "iopub.status.idle": "2023-06-04T04:09:28.012778Z",
     "shell.execute_reply": "2023-06-04T04:09:28.011829Z"
    },
    "papermill": {
     "duration": 0.052267,
     "end_time": "2023-06-04T04:09:28.014764",
     "exception": false,
     "start_time": "2023-06-04T04:09:27.962497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "\n",
    "# def custom_rpn_cls_loss(logits, labels, num_hard=2):\n",
    "        \n",
    "# #     classify_loss = nn.BCELoss()\n",
    "# #     probs = torch.sigmoid(logits)[:] #.view(-1, 1)\n",
    "# #     pos_idcs = labels[:] == 1\n",
    "# #     pos_prob = probs[pos_idcs]\n",
    "# #     pos_labels = labels[pos_idcs]\n",
    "\n",
    "# #     neg_idcs = labels[:] == 0\n",
    "# #     neg_prob = probs[neg_idcs]\n",
    "# #     neg_labels = labels[neg_idcs]\n",
    "#     p_indices = torch.where(labels == 1)\n",
    "#     n_indices = torch.where(labels == 0)\n",
    "# #     print('NUM', p_indices[0].shape, n_indices[0].shape)\n",
    "#     if mode == 'valid': \n",
    "#         num_hard=1000000000\n",
    "#         val_rpn_pos_per_batch.append(p_indices[0].shape)\n",
    "#         val_rpn_neg_per_batch.append(n_indices[0].shape) \n",
    "#     else :\n",
    "#         rpn_pos_per_batch.append(p_indices[0].shape)\n",
    "#         rpn_neg_per_batch.append(n_indices[0].shape)\n",
    "    \n",
    "# #     if num_hard > 0:\n",
    "# #         neg_prob, neg_labels = OHEM(neg_prob, neg_labels, num_hard * len(pos_prob))\n",
    "\n",
    "# #     pos_correct = 0\n",
    "# #     pos_total = 0\n",
    "# #     if len(pos_prob) > 0:\n",
    "# #         cls_loss = 0.5 * classify_loss(\n",
    "# #             pos_prob, pos_labels.float()) + 0.5 * classify_loss(\n",
    "# #             neg_prob, neg_labels.float())\n",
    "# #         pos_correct = (pos_prob >= 0.5).sum()\n",
    "# #         pos_total = len(pos_prob)\n",
    "# #     else:\n",
    "# #         cls_loss = 0.5 * classify_loss(\n",
    "# #             neg_prob, neg_labels.float())\n",
    "\n",
    "\n",
    "# #     neg_correct = (neg_prob < 0.5).sum()\n",
    "# #     neg_total = len(neg_prob)\n",
    "#     return F.binary_cross_entropy_with_logits(logits, labels)#cls_loss #pos_correct, pos_total, neg_correct, neg_total\n",
    "\n",
    "\n",
    "# def OHEM(neg_output, neg_labels, num_hard):\n",
    "#     _, idcs = torch.topk(neg_output, min(num_hard, len(neg_output)))\n",
    "#     neg_output = torch.index_select(neg_output, 0, idcs)\n",
    "#     neg_labels = torch.index_select(neg_labels, 0, idcs)\n",
    "#     return neg_output, neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acb35bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:09:28.103716Z",
     "iopub.status.busy": "2023-06-04T04:09:28.103425Z",
     "iopub.status.idle": "2023-06-04T04:09:28.109991Z",
     "shell.execute_reply": "2023-06-04T04:09:28.109073Z"
    },
    "papermill": {
     "duration": 0.053459,
     "end_time": "2023-06-04T04:09:28.112025",
     "exception": false,
     "start_time": "2023-06-04T04:09:28.058566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def custom_rcnn_loss(class_logits, box_regression, labels, regression_targets):\n",
    "#     # type: (Tensor, Tensor, List[Tensor], List[Tensor]) -> Tuple[Tensor, Tensor]\n",
    "#     \"\"\"\n",
    "#     Computes the loss for Faster R-CNN.\n",
    "\n",
    "#     Args:\n",
    "#         class_logits (Tensor)\n",
    "#         box_regression (Tensor)\n",
    "#         labels (list[BoxList])\n",
    "#         regression_targets (Tensor)\n",
    "\n",
    "#     Returns:\n",
    "#         classification_loss (Tensor)\n",
    "#         box_loss (Tensor)\n",
    "#     \"\"\"\n",
    "\n",
    "#     labels = torch.cat(labels, dim=0)\n",
    "#     regression_targets = torch.cat(regression_targets, dim=0)\n",
    "    \n",
    "#     batch_size, num_class = class_logits.shape[:2]\n",
    "# #     print('Samuel')\n",
    "#     weight = torch.ones(num_class)\n",
    "#     if torch.cuda.is_available():\n",
    "#         weight = weight.cuda()\n",
    "# #     print('Samuel222')\n",
    "#     total = len(labels)\n",
    "# #     print('Samuel3333')\n",
    "#     for i in range(num_class):\n",
    "#         num_pos = float((labels == i).sum())\n",
    "#         num_pos = max(num_pos, 1)\n",
    "#         weight[i] = total / num_pos\n",
    "    \n",
    "# #     print('Samuel444')\n",
    "#     weight = weight / weight.sum()\n",
    "# #     print('Samuel5555')\n",
    "\n",
    "#     classification_loss = F.cross_entropy(class_logits, labels, weight=weight)\n",
    "\n",
    "#     # get indices that correspond to the regression targets for\n",
    "#     # the corresponding ground truth labels, to be used with\n",
    "#     # advanced indexing\n",
    "#     sampled_pos_inds_subset = torch.where(labels > 0)[0]\n",
    "#     labels_pos = labels[sampled_pos_inds_subset]\n",
    "#     N, num_classes = class_logits.shape\n",
    "#     box_regression = box_regression.reshape(N, box_regression.size(-1) // 4, 4)\n",
    "\n",
    "#     box_loss = F.smooth_l1_loss(\n",
    "#         box_regression[sampled_pos_inds_subset, labels_pos],\n",
    "#         regression_targets[sampled_pos_inds_subset],\n",
    "#         beta=1 / 9,\n",
    "#         reduction=\"sum\",\n",
    "#     )\n",
    "#     box_loss = box_loss / labels.numel()\n",
    "\n",
    "#     return classification_loss, box_loss\n",
    "\n",
    "# def fastrcnn_loss(class_logits, box_regression, labels, regression_targets):\n",
    "#     # type: (Tensor, Tensor, List[Tensor], List[Tensor]) -> Tuple[Tensor, Tensor]\n",
    "#     \"\"\"\n",
    "#     Computes the loss for Faster R-CNN.\n",
    "\n",
    "#     Args:\n",
    "#         class_logits (Tensor)\n",
    "#         box_regression (Tensor)\n",
    "#         labels (list[BoxList])\n",
    "#         regression_targets (Tensor)\n",
    "\n",
    "#     Returns:\n",
    "#         classification_loss (Tensor)\n",
    "#         box_loss (Tensor)\n",
    "#     \"\"\"\n",
    "\n",
    "#     labels = torch.cat(labels, dim=0)\n",
    "#     regression_targets = torch.cat(regression_targets, dim=0)\n",
    "\n",
    "#     classification_loss = F.cross_entropy(class_logits, labels)\n",
    "\n",
    "#     # get indices that correspond to the regression targets for\n",
    "#     # the corresponding ground truth labels, to be used with\n",
    "#     # advanced indexing\n",
    "#     sampled_pos_inds_subset = torch.where(labels > 0)[0]\n",
    "#     labels_pos = labels[sampled_pos_inds_subset]\n",
    "#     N, num_classes = class_logits.shape\n",
    "#     box_regression = box_regression.reshape(N, box_regression.size(-1) // 4, 4)\n",
    "\n",
    "#     box_loss = F.smooth_l1_loss(\n",
    "#         box_regression[sampled_pos_inds_subset, labels_pos],\n",
    "#         regression_targets[sampled_pos_inds_subset],\n",
    "#         beta=1 / 9,\n",
    "#         reduction=\"sum\",\n",
    "#     )\n",
    "#     box_loss = box_loss / labels.numel()\n",
    "\n",
    "#     return classification_loss, box_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "789773c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:09:28.203734Z",
     "iopub.status.busy": "2023-06-04T04:09:28.203420Z",
     "iopub.status.idle": "2023-06-04T04:09:28.216100Z",
     "shell.execute_reply": "2023-06-04T04:09:28.215295Z"
    },
    "papermill": {
     "duration": 0.06126,
     "end_time": "2023-06-04T04:09:28.217978",
     "exception": false,
     "start_time": "2023-06-04T04:09:28.156718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torchvision.models.detection.roi_heads import RoIHeads\n",
    "# from torchvision.models.detection import _utils as det_utils\n",
    "\n",
    "# class CustomRoIHead(RoIHeads):\n",
    "#     __annotations__ = {\n",
    "#         \"box_coder\": det_utils.BoxCoder,\n",
    "#         \"proposal_matcher\": det_utils.Matcher,\n",
    "#         \"fg_bg_sampler\": det_utils.BalancedPositiveNegativeSampler,\n",
    "#     }\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         box_roi_pool,\n",
    "#         box_head,\n",
    "#         box_predictor,\n",
    "#         # Faster R-CNN training\n",
    "#         fg_iou_thresh,\n",
    "#         bg_iou_thresh,\n",
    "#         batch_size_per_image,\n",
    "#         positive_fraction,\n",
    "#         bbox_reg_weights,\n",
    "#         # Faster R-CNN inference\n",
    "#         score_thresh,\n",
    "#         nms_thresh,\n",
    "#         detections_per_img,\n",
    "#         # Mask\n",
    "#         mask_roi_pool=None,\n",
    "#         mask_head=None,\n",
    "#         mask_predictor=None,\n",
    "#         keypoint_roi_pool=None,\n",
    "#         keypoint_head=None,\n",
    "#         keypoint_predictor=None,\n",
    "#     ):\n",
    "#         super().__init__(box_roi_pool,\n",
    "#         box_head,\n",
    "#         box_predictor,\n",
    "#         # Faster R-CNN training\n",
    "#         fg_iou_thresh,\n",
    "#         bg_iou_thresh,\n",
    "#         batch_size_per_image,\n",
    "#         positive_fraction,\n",
    "#         bbox_reg_weights,\n",
    "#         # Faster R-CNN inference\n",
    "#         score_thresh,\n",
    "#         nms_thresh,\n",
    "#         detections_per_img,\n",
    "#         # Mask\n",
    "#         mask_roi_pool,\n",
    "#         mask_head,\n",
    "#         mask_predictor,\n",
    "#         keypoint_roi_pool,\n",
    "#         keypoint_head,\n",
    "#         keypoint_predictor,\n",
    "#         )\n",
    "        \n",
    "#     def forward(\n",
    "#         self,\n",
    "#         features,  # type: Dict[str, Tensor]\n",
    "#         proposals,  # type: List[Tensor]\n",
    "#         image_shapes,  # type: List[Tuple[int, int]]\n",
    "#         targets=None,  # type: Optional[List[Dict[str, Tensor]]]\n",
    "#     ):\n",
    "#         # type: (...) -> Tuple[List[Dict[str, Tensor]], Dict[str, Tensor]]\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             features (List[Tensor])\n",
    "#             proposals (List[Tensor[N, 4]])\n",
    "#             image_shapes (List[Tuple[H, W]])\n",
    "#             targets (List[Dict])\n",
    "#         \"\"\"\n",
    "#         if targets is not None:\n",
    "#             for t in targets:\n",
    "#                 # TODO: https://github.com/pytorch/pytorch/issues/26731\n",
    "#                 floating_point_types = (torch.float, torch.double, torch.half)\n",
    "#                 if not t[\"boxes\"].dtype in floating_point_types:\n",
    "#                     raise TypeError(f\"target boxes must of float type, instead got {t['boxes'].dtype}\")\n",
    "#                 if not t[\"labels\"].dtype == torch.int64:\n",
    "#                     raise TypeError(f\"target labels must of int64 type, instead got {t['labels'].dtype}\")\n",
    "#                 if self.has_keypoint():\n",
    "#                     if not t[\"keypoints\"].dtype == torch.float32:\n",
    "#                         raise TypeError(f\"target keypoints must of float type, instead got {t['keypoints'].dtype}\")\n",
    "\n",
    "#         if self.training:\n",
    "#             proposals, matched_idxs, labels, regression_targets = self.select_training_samples(proposals, targets)\n",
    "#         else:\n",
    "#             labels = None\n",
    "#             regression_targets = None\n",
    "#             matched_idxs = None\n",
    "\n",
    "#         box_features = self.box_roi_pool(features, proposals, image_shapes)\n",
    "#         box_features = self.box_head(box_features)\n",
    "#         class_logits, box_regression = self.box_predictor(box_features)\n",
    "\n",
    "#         result: List[Dict[str, torch.Tensor]] = []\n",
    "#         losses = {}\n",
    "#         if self.training:\n",
    "#             if labels is None:\n",
    "#                 raise ValueError(\"labels cannot be None\")\n",
    "#             if regression_targets is None:\n",
    "#                 raise ValueError(\"regression_targets cannot be None\")\n",
    "#             loss_classifier, loss_box_reg = custom_rcnn_loss(class_logits, box_regression, labels, regression_targets)\n",
    "#             losses = {\"loss_classifier\": loss_classifier, \"loss_box_reg\": loss_box_reg}\n",
    "#         else:\n",
    "#             boxes, scores, labels = self.postprocess_detections(class_logits, box_regression, proposals, image_shapes)\n",
    "#             num_images = len(boxes)\n",
    "#             for i in range(num_images):\n",
    "#                 result.append(\n",
    "#                     {\n",
    "#                         \"boxes\": boxes[i],\n",
    "#                         \"labels\": labels[i],\n",
    "#                         \"scores\": scores[i],\n",
    "#                     }\n",
    "#                 )\n",
    "\n",
    "#         if self.has_mask():\n",
    "#             mask_proposals = [p[\"boxes\"] for p in result]\n",
    "#             if self.training:\n",
    "#                 if matched_idxs is None:\n",
    "#                     raise ValueError(\"if in training, matched_idxs should not be None\")\n",
    "\n",
    "#                 # during training, only focus on positive boxes\n",
    "#                 num_images = len(proposals)\n",
    "#                 mask_proposals = []\n",
    "#                 pos_matched_idxs = []\n",
    "#                 for img_id in range(num_images):\n",
    "#                     pos = torch.where(labels[img_id] > 0)[0]\n",
    "#                     mask_proposals.append(proposals[img_id][pos])\n",
    "#                     pos_matched_idxs.append(matched_idxs[img_id][pos])\n",
    "#             else:\n",
    "#                 pos_matched_idxs = None\n",
    "\n",
    "#             if self.mask_roi_pool is not None:\n",
    "#                 mask_features = self.mask_roi_pool(features, mask_proposals, image_shapes)\n",
    "#                 mask_features = self.mask_head(mask_features)\n",
    "#                 mask_logits = self.mask_predictor(mask_features)\n",
    "#             else:\n",
    "#                 raise Exception(\"Expected mask_roi_pool to be not None\")\n",
    "\n",
    "#             loss_mask = {}\n",
    "#             if self.training:\n",
    "#                 if targets is None or pos_matched_idxs is None or mask_logits is None:\n",
    "#                     raise ValueError(\"targets, pos_matched_idxs, mask_logits cannot be None when training\")\n",
    "\n",
    "#                 gt_masks = [t[\"masks\"] for t in targets]\n",
    "#                 gt_labels = [t[\"labels\"] for t in targets]\n",
    "#                 rcnn_loss_mask = maskrcnn_loss(mask_logits, mask_proposals, gt_masks, gt_labels, pos_matched_idxs)\n",
    "#                 loss_mask = {\"loss_mask\": rcnn_loss_mask}\n",
    "#             else:\n",
    "#                 labels = [r[\"labels\"] for r in result]\n",
    "#                 masks_probs = maskrcnn_inference(mask_logits, labels)\n",
    "#                 for mask_prob, r in zip(masks_probs, result):\n",
    "#                     r[\"masks\"] = mask_prob\n",
    "\n",
    "#             losses.update(loss_mask)\n",
    "\n",
    "#         # keep none checks in if conditional so torchscript will conditionally\n",
    "#         # compile each branch\n",
    "#         if (\n",
    "#             self.keypoint_roi_pool is not None\n",
    "#             and self.keypoint_head is not None\n",
    "#             and self.keypoint_predictor is not None\n",
    "#         ):\n",
    "#             keypoint_proposals = [p[\"boxes\"] for p in result]\n",
    "#             if self.training:\n",
    "#                 # during training, only focus on positive boxes\n",
    "#                 num_images = len(proposals)\n",
    "#                 keypoint_proposals = []\n",
    "#                 pos_matched_idxs = []\n",
    "#                 if matched_idxs is None:\n",
    "#                     raise ValueError(\"if in trainning, matched_idxs should not be None\")\n",
    "\n",
    "#                 for img_id in range(num_images):\n",
    "#                     pos = torch.where(labels[img_id] > 0)[0]\n",
    "#                     keypoint_proposals.append(proposals[img_id][pos])\n",
    "#                     pos_matched_idxs.append(matched_idxs[img_id][pos])\n",
    "#             else:\n",
    "#                 pos_matched_idxs = None\n",
    "\n",
    "#             keypoint_features = self.keypoint_roi_pool(features, keypoint_proposals, image_shapes)\n",
    "#             keypoint_features = self.keypoint_head(keypoint_features)\n",
    "#             keypoint_logits = self.keypoint_predictor(keypoint_features)\n",
    "\n",
    "#             loss_keypoint = {}\n",
    "#             if self.training:\n",
    "#                 if targets is None or pos_matched_idxs is None:\n",
    "#                     raise ValueError(\"both targets and pos_matched_idxs should not be None when in training mode\")\n",
    "\n",
    "#                 gt_keypoints = [t[\"keypoints\"] for t in targets]\n",
    "#                 rcnn_loss_keypoint = keypointrcnn_loss(\n",
    "#                     keypoint_logits, keypoint_proposals, gt_keypoints, pos_matched_idxs\n",
    "#                 )\n",
    "#                 loss_keypoint = {\"loss_keypoint\": rcnn_loss_keypoint}\n",
    "#             else:\n",
    "#                 if keypoint_logits is None or keypoint_proposals is None:\n",
    "#                     raise ValueError(\n",
    "#                         \"both keypoint_logits and keypoint_proposals should not be None when not in training mode\"\n",
    "#                     )\n",
    "\n",
    "#                 keypoints_probs, kp_scores = keypointrcnn_inference(keypoint_logits, keypoint_proposals)\n",
    "#                 for keypoint_prob, kps, r in zip(keypoints_probs, kp_scores, result):\n",
    "#                     r[\"keypoints\"] = keypoint_prob\n",
    "#                     r[\"keypoints_scores\"] = kps\n",
    "#             losses.update(loss_keypoint)\n",
    "\n",
    "#         return result, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f20bf37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:09:28.308134Z",
     "iopub.status.busy": "2023-06-04T04:09:28.307842Z",
     "iopub.status.idle": "2023-06-04T04:09:28.316615Z",
     "shell.execute_reply": "2023-06-04T04:09:28.315807Z"
    },
    "id": "bEnRtOTOl6e1",
    "outputId": "e3beebee-dc5f-4b9c-8b0d-a266e2900d45",
    "papermill": {
     "duration": 0.056409,
     "end_time": "2023-06-04T04:09:28.318611",
     "exception": false,
     "start_time": "2023-06-04T04:09:28.262202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "# from torchvision.models.detection.rpn import AnchorGenerator\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.models as models\n",
    "# from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "# from torch import Tensor\n",
    "# from typing import Tuple, List, Dict\n",
    "# import torchvision.ops as ops\n",
    "# from torchvision.models.detection.faster_rcnn import TwoMLPHead\n",
    "\n",
    "# model = models.detection.fasterrcnn_resnet50_fpn(pretrained=pretrain)\n",
    "# model.transform = GeneralizedRCNNTransform(512,512,[0, 0, 0], [1, 1, 1])\n",
    "# model.backbone.body.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
    "\n",
    "\n",
    "# # rpn replace \n",
    "# from torchvision.models.detection.rpn import RegionProposalNetwork\n",
    "# from torchvision.models.detection.rpn import RPNHead\n",
    "# class CustomRPN(RegionProposalNetwork):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         anchor_generator: AnchorGenerator,\n",
    "#         head: nn.Module,\n",
    "#         # Faster-RCNN Training\n",
    "#         fg_iou_thresh: float,\n",
    "#         bg_iou_thresh: float,\n",
    "#         batch_size_per_image: int,\n",
    "#         positive_fraction: float,\n",
    "#         # Faster-RCNN Inference\n",
    "#         pre_nms_top_n: Dict[str, int],\n",
    "#         post_nms_top_n: Dict[str, int],\n",
    "#         nms_thresh: float,\n",
    "#         score_thresh: float = 0.0,\n",
    "#     ) -> None:\n",
    "#         super().__init__(anchor_generator, head, fg_iou_thresh, bg_iou_thresh, batch_size_per_image, positive_fraction, pre_nms_top_n, post_nms_top_n, nms_thresh, score_thresh)\n",
    "\n",
    "#     def compute_loss(\n",
    "#         self, objectness: Tensor, pred_bbox_deltas: Tensor, labels: List[Tensor], regression_targets: List[Tensor]\n",
    "#     ) -> Tuple[Tensor, Tensor]:\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             objectness (Tensor)\n",
    "#             pred_bbox_deltas (Tensor)\n",
    "#             labels (List[Tensor])\n",
    "#             regression_targets (List[Tensor])\n",
    "\n",
    "#         Returns:\n",
    "#             objectness_loss (Tensor)\n",
    "#             box_loss (Tensor)\n",
    "#         \"\"\"\n",
    "\n",
    "#         sampled_pos_inds, sampled_neg_inds = self.fg_bg_sampler(labels)\n",
    "# #         print('sampled_pos_inds', type(sampled_pos_inds[0]), sampled_pos_inds[0].shape)\n",
    "# #         print('sampled_neg_inds', type(sampled_neg_inds[0]), sampled_neg_inds[0].shape)\n",
    "        \n",
    "#         sampled_pos_inds = torch.where(torch.cat(sampled_pos_inds, dim=0))[0]\n",
    "#         sampled_neg_inds = torch.where(torch.cat(sampled_neg_inds, dim=0))[0]\n",
    "\n",
    "#         sampled_inds = torch.cat([sampled_pos_inds, sampled_neg_inds], dim=0)\n",
    "\n",
    "#         objectness = objectness.flatten()\n",
    "\n",
    "#         labels = torch.cat(labels, dim=0)\n",
    "#         regression_targets = torch.cat(regression_targets, dim=0)\n",
    "\n",
    "#         box_loss = F.smooth_l1_loss(\n",
    "#             pred_bbox_deltas[sampled_pos_inds],\n",
    "#             regression_targets[sampled_pos_inds],\n",
    "#             beta=1 / 9,\n",
    "#             reduction=\"sum\",\n",
    "#         ) / (sampled_inds.numel())\n",
    "#         objectness_loss = custom_rpn_cls_loss(objectness[sampled_inds], labels[sampled_inds]) # F.binary_cross_entropy_with_logits\n",
    "\n",
    "#         return objectness_loss, box_loss\n",
    "# aspect_ratios = [(0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0)]\n",
    "# sizes = ((4,), (8,), (16,), (32,), (64,)) \n",
    "# model.rpn =  CustomRPN(AnchorGenerator(sizes=sizes, aspect_ratios=aspect_ratios), RPNHead(256, 15), 0.7, 0.3, 256, 0.5, {'training': 12000, 'testing': 3000}, {'training': 600, 'testing': 300}, 0.7)\n",
    "\n",
    "# in_feature = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# model.roi_heads.box_predictor =FastRCNNPredictor(in_feature, 2)\n",
    "# # model.roi_heads = CustomRoIHead(ops.MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2),\n",
    "# #                                 TwoMLPHead(12544, 1024),\n",
    "# #                                 FastRCNNPredictor(in_feature, 2),\n",
    "# #                                 fg_iou_thresh = 0.5,\n",
    "# #                                 bg_iou_thresh = 0.5,\n",
    "# #                                 score_thresh = 0.05,\n",
    "# #                                 nms_thresh = 0.5,\n",
    "# #                                 detections_per_img = 100,\n",
    "# #                                 batch_size_per_image = 512,\n",
    "# #                                 positive_fraction = 0.25,\n",
    "# #                                 bbox_reg_weights = None,\n",
    "# #                                 )\n",
    "# # 'box_roi_pool', 'box_head', 'box_predictor', 'fg_iou_thresh', \n",
    "# # 'bg_iou_thresh', 'batch_size_per_image', 'positive_fraction', 'bbox_reg_weights', \n",
    "# # 'score_thresh', 'nms_thresh', and 'detections_per_img'\n",
    "\n",
    "# # print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad143bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:09:28.407391Z",
     "iopub.status.busy": "2023-06-04T04:09:28.407117Z",
     "iopub.status.idle": "2023-06-04T04:09:30.460597Z",
     "shell.execute_reply": "2023-06-04T04:09:30.459581Z"
    },
    "papermill": {
     "duration": 2.102899,
     "end_time": "2023-06-04T04:09:30.465453",
     "exception": false,
     "start_time": "2023-06-04T04:09:28.362554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 233MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FasterRCNN(\n",
      "  (transform): GeneralizedRCNNTransform(\n",
      "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "      Resize(min_size=(512,), max_size=512, mode='bilinear')\n",
      "  )\n",
      "  (backbone): BackboneWithFPN(\n",
      "    (body): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fpn): FeaturePyramidNetwork(\n",
      "      (inner_blocks): ModuleList(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (layer_blocks): ModuleList(\n",
      "        (0-3): 4 x Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (extra_blocks): LastLevelMaxPool()\n",
      "    )\n",
      "  )\n",
      "  (rpn): RegionProposalNetwork(\n",
      "    (anchor_generator): AnchorGenerator()\n",
      "    (head): RPNHead(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RoIHeads(\n",
      "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
      "    (box_head): TwoMLPHead(\n",
      "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNPredictor(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "\n",
    "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "model.transform = GeneralizedRCNNTransform(512,512,[0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "in_feature = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_feature, 2)\n",
    "model.backbone.body.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
    "\n",
    "aspect_ratios = [(0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0)]\n",
    "sizes = ((4,), (8,), (16,), (32,), (64,)) \n",
    "model.rpn.anchor_generator = AnchorGenerator(sizes=sizes, aspect_ratios=aspect_ratios)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "054a0f80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:09:30.559628Z",
     "iopub.status.busy": "2023-06-04T04:09:30.559331Z",
     "iopub.status.idle": "2023-06-04T04:09:30.566455Z",
     "shell.execute_reply": "2023-06-04T04:09:30.565582Z"
    },
    "id": "ILsIzzsfvj0K",
    "papermill": {
     "duration": 0.056278,
     "end_time": "2023-06-04T04:09:30.568522",
     "exception": false,
     "start_time": "2023-06-04T04:09:30.512244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bbox_iou(bbox_a, bbox_b):\n",
    "    if bbox_a.shape[1]!=4 or bbox_b.shape[1]!=4:\n",
    "        raise IndexError\n",
    "    tl = np.maximum(bbox_a[:, None, :2], bbox_b[:, :2])\n",
    "    br = np.minimum(bbox_a[:, None, 2:], bbox_b[:, 2:])\n",
    "\n",
    "    area_i = np.prod(br-tl, axis=2) * (tl<br).all(axis=2)\n",
    "    area_a = np.prod(bbox_a[:, 2:] - bbox_a[:, :2], axis=1)\n",
    "    area_b = np.prod(bbox_b[:, 2:] - bbox_b[:, :2], axis=1)\n",
    "\n",
    "    return area_i / (area_a[:, None] + area_b - area_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e3169b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:09:30.661376Z",
     "iopub.status.busy": "2023-06-04T04:09:30.659774Z",
     "iopub.status.idle": "2023-06-04T04:09:30.667523Z",
     "shell.execute_reply": "2023-06-04T04:09:30.666228Z"
    },
    "id": "XbdoAothzdlA",
    "outputId": "5bdc0bc1-8c91-4d55-e736-84917a059295",
    "papermill": {
     "duration": 0.055613,
     "end_time": "2023-06-04T04:09:30.669582",
     "exception": false,
     "start_time": "2023-06-04T04:09:30.613969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ious [[0.10810811 0.        ]\n",
      " [0.17142857 0.        ]]\n",
      "max_ious <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "ious = bbox_iou(np.array([[1,1,6,6], [5,1,10,6]]), np.array([[4,4,8,8],[9,9,10,10]]))\n",
    "print('ious', ious)\n",
    "max_ious = np.max(ious, axis=1)\n",
    "print('max_ious', type(max_ious))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2ec1e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T04:09:30.761926Z",
     "iopub.status.busy": "2023-06-04T04:09:30.761612Z",
     "iopub.status.idle": "2023-06-04T09:41:34.982257Z",
     "shell.execute_reply": "2023-06-04T09:41:34.981370Z"
    },
    "id": "5lNrA0QlQhbT",
    "outputId": "a1fb5465-a17c-4b09-d00f-15a09ff7d715",
    "papermill": {
     "duration": 19924.322712,
     "end_time": "2023-06-04T09:41:35.037971",
     "exception": false,
     "start_time": "2023-06-04T04:09:30.715259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training (unfreeze ResNet50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]/tmp/ipykernel_23/2369231521.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  image = torch.tensor(image)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 nan valid_num :  0\n",
      "valid_iou :  nan valid_num :  0\n",
      "valid_recall :  0.0\n",
      "valid_precision :  0\n",
      "===================LOSS========================\n",
      "loss :  0.002211106784523514 0.04280909249048413 0.003580369986571057 0.03023055855712833\n",
      "val_loss :  0.001981771089976617 0.016761997312891717 0.005456737365902346 0.019491935733194445\n",
      "epoch :  0 ,train_loss :  0.07883112759233635 ,valid_loss :  0.043692441657185555\n",
      "saving model weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  2%|▎         | 1/40 [08:18<5:24:19, 498.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 nan valid_num :  0\n",
      "valid_iou :  nan valid_num :  0\n",
      "valid_recall :  0.0\n",
      "valid_precision :  0\n",
      "===================LOSS========================\n",
      "loss :  0.0018548050886629342 0.014409179588913268 0.00522487458261691 0.016955620606322525\n",
      "val_loss :  0.0020226843954137 0.015681596372422633 0.006306750202259305 0.018460940642684113\n",
      "epoch :  1 ,train_loss :  0.038444480031868004 ,valid_loss :  0.042471971618486384\n",
      "saving model weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [24:53<5:06:47, 497.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 nan valid_num :  0\n",
      "valid_iou :  nan valid_num :  0\n",
      "valid_recall :  0.0\n",
      "valid_precision :  0\n",
      "===================LOSS========================\n",
      "loss :  0.0018441671691617329 0.013006656243526768 0.0070516094384059265 0.016927807961773372\n",
      "val_loss :  0.002012706655031983 0.014072016173718022 0.008234613903743379 0.020167642610841523\n",
      "epoch :  2 ,train_loss :  0.03883024076191343 ,valid_loss :  0.04448697902262211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [33:10<4:58:27, 497.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 nan valid_num :  0\n",
      "valid_iou :  nan valid_num :  0\n",
      "valid_recall :  0.0\n",
      "valid_precision :  0\n",
      "===================LOSS========================\n",
      "loss :  0.001823027145405477 0.01139510874679991 0.00851562340283981 0.017316077088768887\n",
      "val_loss :  0.0020177265019703876 0.012463928200304508 0.009251838878673665 0.020619209454047913\n",
      "epoch :  3 ,train_loss :  0.03904983661836738 ,valid_loss :  0.044352702650369384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [41:27<4:50:08, 497.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 nan valid_num :  0\n",
      "valid_iou :  nan valid_num :  0\n",
      "valid_recall :  0.0\n",
      "valid_precision :  0\n",
      "===================LOSS========================\n",
      "loss :  0.0018125472097466134 0.009977152676980164 0.00934241184090029 0.017298358621661816\n",
      "val_loss :  0.0020009915107021144 0.010996580799566764 0.010249870190141248 0.019542491154781745\n",
      "epoch :  4 ,train_loss :  0.038430470378483385 ,valid_loss :  0.04278993387432659\n",
      "===================ROI========================\n",
      "roi_over_0.5 nan valid_num :  0\n",
      "valid_iou :  nan valid_num :  0\n",
      "valid_recall :  0.0\n",
      "valid_precision :  0\n",
      "===================LOSS========================\n",
      "loss :  0.0017961447245573388 0.008738347216047973 0.01033204660959095 0.017259321658584837\n",
      "val_loss :  0.001997883691265266 0.010105746743433616 0.010628201049186435 0.019196071205478088\n",
      "epoch :  5 ,train_loss :  0.03812586021757571 ,valid_loss :  0.04192790250275649\n",
      "saving model weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [58:02<4:33:38, 497.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 nan valid_num :  0\n",
      "valid_iou :  nan valid_num :  0\n",
      "valid_recall :  0.0\n",
      "valid_precision :  0\n",
      "===================LOSS========================\n",
      "loss :  0.0017812775787600023 0.007963562060750998 0.010815503864196952 0.016687753179467447\n",
      "val_loss :  0.0020394122944779546 0.009978417380183352 0.012528038008467239 0.02047694184105186\n",
      "epoch :  6 ,train_loss :  0.037248096655114235 ,valid_loss :  0.045022809403199776\n",
      "===================ROI========================\n",
      "roi_over_0.5 0.5893192653392652 valid_num :  2\n",
      "valid_iou :  0.6547894419181968 valid_num :  3\n",
      "valid_recall :  0.0027397260273972603\n",
      "valid_precision :  0.5\n",
      "===================LOSS========================\n",
      "loss :  0.0017576716411235014 0.007194264039014266 0.011398074049589651 0.015950756498563142\n",
      "val_loss :  0.002014324576913507 0.008924599463010536 0.012397974373444039 0.01857746461881142\n",
      "epoch :  7 ,train_loss :  0.036300766319500695 ,valid_loss :  0.041914363446481084\n",
      "saving model weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 8/40 [1:06:20<4:25:25, 497.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.4995441049131225 valid_num :  32\n",
      "valid_iou :  0.5016881755109662 valid_num :  33\n",
      "valid_recall :  0.049315068493150684\n",
      "valid_precision :  0.5\n",
      "===================LOSS========================\n",
      "loss :  0.00175306827910288 0.006504201435054598 0.011866017223721678 0.015301812344413494\n",
      "val_loss :  0.0019759223339896577 0.008852225381369684 0.012006438437703193 0.017133263953249243\n",
      "epoch :  8 ,train_loss :  0.03542509916415467 ,valid_loss :  0.0399678503254465\n",
      "saving model weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 9/40 [1:14:38<4:17:11, 497.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.43495789205927315 valid_num :  68\n",
      "valid_iou :  0.43495789205927315 valid_num :  68\n",
      "valid_recall :  0.08767123287671233\n",
      "valid_precision :  0.43243243243243246\n",
      "===================LOSS========================\n",
      "loss :  0.00173703785855149 0.005987405402707719 0.012318296746040383 0.014664171304193984\n",
      "val_loss :  0.0019725323905803115 0.008392753791721427 0.01217298315582322 0.01697149628079405\n",
      "epoch :  9 ,train_loss :  0.03470691121720079 ,valid_loss :  0.039509765730769024\n",
      "saving model weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [1:31:15<4:00:38, 497.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.4052445380802911 valid_num :  190\n",
      "valid_iou :  0.4052445380802911 valid_num :  190\n",
      "valid_recall :  0.19452054794520549\n",
      "valid_precision :  0.35858585858585856\n",
      "===================LOSS========================\n",
      "loss :  0.0017214818864682185 0.005527674983911263 0.012313324418803822 0.014108359382119367\n",
      "val_loss :  0.002047182179476116 0.009049517696029415 0.014172143193290514 0.018737412222168025\n",
      "epoch :  10 ,train_loss :  0.033670840731232984 ,valid_loss :  0.04400625536400898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [1:39:32<3:52:18, 497.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.39545792343427644 valid_num :  88\n",
      "valid_iou :  0.39545792343427644 valid_num :  88\n",
      "valid_recall :  0.09041095890410959\n",
      "valid_precision :  0.336734693877551\n",
      "===================LOSS========================\n",
      "loss :  0.0017033619747237473 0.00506732345999703 0.012755679225583917 0.013731582875790023\n",
      "val_loss :  0.002041936600946036 0.008141796442442666 0.013962273079646276 0.018854867046078045\n",
      "epoch :  11 ,train_loss :  0.03325794754706532 ,valid_loss :  0.043000873068676275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [1:47:50<3:43:59, 497.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.4257246198499661 valid_num :  105\n",
      "valid_iou :  0.4269920486788191 valid_num :  106\n",
      "valid_recall :  0.1178082191780822\n",
      "valid_precision :  0.36752136752136755\n",
      "===================LOSS========================\n",
      "loss :  0.0016891288891473838 0.004797446541850835 0.013095604792539019 0.013379727564229865\n",
      "val_loss :  0.002007677226656062 0.007941618283260978 0.014079940770113585 0.01830167892188126\n",
      "epoch :  12 ,train_loss :  0.032961907758844604 ,valid_loss :  0.04233091525441291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [1:56:09<3:35:48, 498.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.37056575135080594 valid_num :  301\n",
      "valid_iou :  0.37056575135080594 valid_num :  301\n",
      "valid_recall :  0.26301369863013696\n",
      "valid_precision :  0.2831858407079646\n",
      "===================LOSS========================\n",
      "loss :  0.0016772035209514995 0.004479425220904042 0.012943245815780489 0.013173075488585735\n",
      "val_loss :  0.0019805330529754214 0.007385375968856262 0.014342470888924949 0.017339414661275407\n",
      "epoch :  13 ,train_loss :  0.03227295014554652 ,valid_loss :  0.04104779485393973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [2:04:27<3:27:37, 498.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.3848235238261033 valid_num :  219\n",
      "valid_iou :  0.3848235238261033 valid_num :  219\n",
      "valid_recall :  0.2136986301369863\n",
      "valid_precision :  0.319672131147541\n",
      "===================LOSS========================\n",
      "loss :  0.0016707549762159204 0.004239475680225038 0.01352287187876406 0.013157707412735881\n",
      "val_loss :  0.001997380355354764 0.0073739702461798695 0.014688011697110008 0.018141007927410743\n",
      "epoch :  14 ,train_loss :  0.0325908098903679 ,valid_loss :  0.04220037038127581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 16/40 [2:12:45<3:19:14, 498.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.647731076058797 valid_num :  22\n",
      "valid_iou :  0.647731076058797 valid_num :  22\n",
      "valid_recall :  0.049315068493150684\n",
      "valid_precision :  0.75\n",
      "===================LOSS========================\n",
      "loss :  0.0016537064102890313 0.004144838563967322 0.013445436398170866 0.01289984592268493\n",
      "val_loss :  0.002099600854539769 0.009404772011490137 0.015985430455675312 0.02969176177958063\n",
      "epoch :  15 ,train_loss :  0.03214382733627458 ,valid_loss :  0.057181564798834274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 17/40 [2:21:03<3:10:54, 498.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.4234325375583889 valid_num :  191\n",
      "valid_iou :  0.4234325375583889 valid_num :  191\n",
      "valid_recall :  0.23013698630136986\n",
      "valid_precision :  0.4077669902912621\n",
      "===================LOSS========================\n",
      "loss :  0.0016426811362123493 0.0038515997035472403 0.01378538998168809 0.012598284707343746\n",
      "val_loss :  0.0019896609535185144 0.0070020897706568825 0.01449607407637671 0.018705060048138395\n",
      "epoch :  16 ,train_loss :  0.031877955491436974 ,valid_loss :  0.0421928843738986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [2:29:20<3:02:32, 497.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.3170624069046477 valid_num :  426\n",
      "valid_iou :  0.3170624069046477 valid_num :  426\n",
      "valid_recall :  0.3315068493150685\n",
      "valid_precision :  0.2542016806722689\n",
      "===================LOSS========================\n",
      "loss :  0.001634158840151997 0.0036222595254371283 0.013671154532047725 0.012390158313248202\n",
      "val_loss :  0.001955069635775598 0.006882404022868357 0.015312020685158525 0.01809532098545163\n",
      "epoch :  17 ,train_loss :  0.03131773104351536 ,valid_loss :  0.04224481532240615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 19/40 [2:37:38<2:54:16, 497.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.367713248665753 valid_num :  433\n",
      "valid_iou :  0.367713248665753 valid_num :  433\n",
      "valid_recall :  0.3863013698630137\n",
      "valid_precision :  0.30387931034482757\n",
      "===================LOSS========================\n",
      "loss :  0.001609907870241107 0.0034926460999299153 0.01433713006282173 0.012148411582569327\n",
      "val_loss :  0.0019800199661403894 0.0070093943367657415 0.01573143141599847 0.018234960497448258\n",
      "epoch :  18 ,train_loss :  0.031588095720462804 ,valid_loss :  0.042955806040588546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [2:45:57<2:46:00, 498.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.44163507806004404 valid_num :  223\n",
      "valid_iou :  0.44163507806004404 valid_num :  223\n",
      "valid_recall :  0.2684931506849315\n",
      "valid_precision :  0.40329218106995884\n",
      "===================LOSS========================\n",
      "loss :  0.0016044633173981444 0.003289548769945749 0.014058648869018085 0.01191657648430528\n",
      "val_loss :  0.001998039542277362 0.007344183617034087 0.016212850955187107 0.019847648665674178\n",
      "epoch :  19 ,train_loss :  0.03086923732135062 ,valid_loss :  0.045402723163658495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [2:54:15<2:37:42, 498.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.4315366523676011 valid_num :  237\n",
      "valid_iou :  0.4315366523676011 valid_num :  237\n",
      "valid_recall :  0.29315068493150687\n",
      "valid_precision :  0.421259842519685\n",
      "===================LOSS========================\n",
      "loss :  0.0015993415551387772 0.0032057288030998034 0.014559401991280996 0.011890189242012498\n",
      "val_loss :  0.0020330651941727483 0.007510632561866706 0.01652079089270795 0.020329515175784334\n",
      "epoch :  20 ,train_loss :  0.0312546616321505 ,valid_loss :  0.04639400381083582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 22/40 [3:02:34<2:29:29, 498.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.3749260732559497 valid_num :  224\n",
      "valid_iou :  0.3749260732559497 valid_num :  224\n",
      "valid_recall :  0.2410958904109589\n",
      "valid_precision :  0.36363636363636365\n",
      "===================LOSS========================\n",
      "loss :  0.0015844503637748506 0.003081020509796594 0.014832930141810408 0.012169971666081207\n",
      "val_loss :  0.002017161634285003 0.007409531728127131 0.016962246850644257 0.021302904623250168\n",
      "epoch :  21 ,train_loss :  0.031668372614732786 ,valid_loss :  0.04769184509767037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 23/40 [3:10:53<2:21:16, 498.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.38061053386269267 valid_num :  280\n",
      "valid_iou :  0.38061053386269267 valid_num :  280\n",
      "valid_recall :  0.3013698630136986\n",
      "valid_precision :  0.36423841059602646\n",
      "===================LOSS========================\n",
      "loss :  0.001586023642412442 0.0029886892702607466 0.015089887584562521 0.011900353206269374\n",
      "val_loss :  0.0019902666065129727 0.006975140523019375 0.0161834883996669 0.020175484922148434\n",
      "epoch :  22 ,train_loss :  0.03156495365572403 ,valid_loss :  0.04532438078347374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [3:19:12<2:12:58, 498.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.34183629734641857 valid_num :  608\n",
      "valid_iou :  0.3424829769975523 valid_num :  609\n",
      "valid_recall :  0.5150684931506849\n",
      "valid_precision :  0.28270676691729324\n",
      "===================LOSS========================\n",
      "loss :  0.0015718356783812244 0.00291449959172992 0.015243139325400286 0.011693756951228063\n",
      "val_loss :  0.0019521947331525677 0.0068907097082439 0.016554844967436557 0.01836415648679523\n",
      "epoch :  23 ,train_loss :  0.03142323149977443 ,valid_loss :  0.04376190608622981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 25/40 [3:27:30<2:04:38, 498.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.3668169649060007 valid_num :  375\n",
      "valid_iou :  0.3668169649060007 valid_num :  375\n",
      "valid_recall :  0.3643835616438356\n",
      "valid_precision :  0.3251833740831296\n",
      "===================LOSS========================\n",
      "loss :  0.0015579145242483826 0.0028099832106874877 0.015315530686044479 0.01155794782976031\n",
      "val_loss :  0.002015544494212258 0.007669278712687539 0.0178826622226659 0.020840926278455584\n",
      "epoch :  24 ,train_loss :  0.031241376275005183 ,valid_loss :  0.04840841180845803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [3:35:48<1:56:15, 498.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.3447048062686076 valid_num :  425\n",
      "valid_iou :  0.3447048062686076 valid_num :  425\n",
      "valid_recall :  0.4054794520547945\n",
      "valid_precision :  0.3231441048034934\n",
      "===================LOSS========================\n",
      "loss :  0.0015525326348197097 0.002681890105273041 0.01598072625954876 0.011513625531286186\n",
      "val_loss :  0.0019907857366727993 0.006985636158645445 0.017165762207963887 0.019700168796321926\n",
      "epoch :  25 ,train_loss :  0.03172877457317812 ,valid_loss :  0.04584235307194438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [3:44:06<1:47:57, 498.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.37180723141909855 valid_num :  353\n",
      "valid_iou :  0.3725070914647081 valid_num :  354\n",
      "valid_recall :  0.34794520547945207\n",
      "valid_precision :  0.3333333333333333\n",
      "===================LOSS========================\n",
      "loss :  0.0015414185829082 0.0025857054213906214 0.016113216756637037 0.011490314555531397\n",
      "val_loss :  0.00203853199263012 0.007802572270270949 0.017421022769721115 0.02181310060561872\n",
      "epoch :  26 ,train_loss :  0.031730655232601074 ,valid_loss :  0.04907522777862409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [3:52:25<1:39:40, 498.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.3181675052665128 valid_num :  607\n",
      "valid_iou :  0.3181675052665128 valid_num :  607\n",
      "valid_recall :  0.4931506849315068\n",
      "valid_precision :  0.2698650674662669\n",
      "===================LOSS========================\n",
      "loss :  0.0015327434089597652 0.0025728843179408088 0.01623943968998077 0.011652516220359718\n",
      "val_loss :  0.0019651731400860146 0.006814882138689213 0.016457550391993103 0.018741258858319593\n",
      "epoch :  27 ,train_loss :  0.031997583674504844 ,valid_loss :  0.04397886447316291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [4:00:43<1:31:22, 498.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.46233967008408294 valid_num :  148\n",
      "valid_iou :  0.46233967008408294 valid_num :  148\n",
      "valid_recall :  0.1917808219178082\n",
      "valid_precision :  0.43209876543209874\n",
      "===================LOSS========================\n",
      "loss :  0.001520005800274224 0.0024949693650687605 0.01644767575528809 0.011211482480870462\n",
      "val_loss :  0.0020901417044703573 0.008452950640097625 0.017935531579104123 0.025354965425589505\n",
      "epoch :  28 ,train_loss :  0.03167413335548847 ,valid_loss :  0.053833589688235636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 30/40 [4:09:01<1:23:01, 498.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.41374197787716666 valid_num :  232\n",
      "valid_iou :  0.41374197787716666 valid_num :  232\n",
      "valid_recall :  0.2821917808219178\n",
      "valid_precision :  0.4153225806451613\n",
      "===================LOSS========================\n",
      "loss :  0.0015115499489388002 0.0023832831308180378 0.01670173811943871 0.011289999537413643\n",
      "val_loss :  0.0020108691864080875 0.007246578329096676 0.018209592950548612 0.023267722670354096\n",
      "epoch :  29 ,train_loss :  0.03188657066915358 ,valid_loss :  0.05073476275976967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [4:17:19<1:14:43, 498.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.3278561328091852 valid_num :  672\n",
      "valid_iou :  0.3278561328091852 valid_num :  672\n",
      "valid_recall :  0.5232876712328767\n",
      "valid_precision :  0.2609289617486339\n",
      "===================LOSS========================\n",
      "loss :  0.0015151693445421477 0.002347525644929923 0.016698153077325903 0.011006034709037372\n",
      "val_loss :  0.0020168678339698588 0.007276006283777237 0.01799374590536543 0.021154251113972244\n",
      "epoch :  30 ,train_loss :  0.031566882587249774 ,valid_loss :  0.04844087088371024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 32/40 [4:25:37<1:06:26, 498.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.3883193327663944 valid_num :  387\n",
      "valid_iou :  0.3883193327663944 valid_num :  387\n",
      "valid_recall :  0.410958904109589\n",
      "valid_precision :  0.35629453681710216\n",
      "===================LOSS========================\n",
      "loss :  0.0015052165523297633 0.002292107398214828 0.016929709437416396 0.011261254583116958\n",
      "val_loss :  0.0020889120687748873 0.008835101162320842 0.018507854428653624 0.02282725992229055\n",
      "epoch :  31 ,train_loss :  0.03198828804959482 ,valid_loss :  0.05225912777378278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 33/40 [4:33:56<58:08, 498.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.40456875711847246 valid_num :  285\n",
      "valid_iou :  0.40456875711847246 valid_num :  285\n",
      "valid_recall :  0.31232876712328766\n",
      "valid_precision :  0.36893203883495146\n",
      "===================LOSS========================\n",
      "loss :  0.0014937486604902012 0.002243403760416033 0.017108759680339296 0.010968431397384711\n",
      "val_loss :  0.0020938934119162605 0.008820665278928537 0.01860235947385138 0.024188052808098933\n",
      "epoch :  32 ,train_loss :  0.03181434348457699 ,valid_loss :  0.0537049703519134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34/40 [4:42:15<49:50, 498.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.38012876901260484 valid_num :  374\n",
      "valid_iou :  0.3809833830214543 valid_num :  375\n",
      "valid_recall :  0.3917808219178082\n",
      "valid_precision :  0.3575\n",
      "===================LOSS========================\n",
      "loss :  0.0014900121788169341 0.0022014733565306854 0.017494892211184138 0.011149464427519625\n",
      "val_loss :  0.0019519470789579347 0.0065756722024696715 0.018268192369563906 0.021119873048555032\n",
      "epoch :  33 ,train_loss :  0.03233584215736881 ,valid_loss :  0.04791568482623381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [4:50:32<41:31, 498.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.34851009290829915 valid_num :  564\n",
      "valid_iou :  0.3488210476378807 valid_num :  565\n",
      "valid_recall :  0.4904109589041096\n",
      "valid_precision :  0.2905844155844156\n",
      "===================LOSS========================\n",
      "loss :  0.00147859108702474 0.0022040711658879116 0.017578921230028258 0.010927307093080795\n",
      "val_loss :  0.0020094396895729005 0.007564294639308297 0.018625325669406678 0.021656164625550017\n",
      "epoch :  34 ,train_loss :  0.03218889070204764 ,valid_loss :  0.049855224349919486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 36/40 [4:58:50<33:12, 498.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.4247476060078446 valid_num :  207\n",
      "valid_iou :  0.4247476060078446 valid_num :  207\n",
      "valid_recall :  0.25753424657534246\n",
      "valid_precision :  0.42152466367713004\n",
      "===================LOSS========================\n",
      "loss :  0.0014799169171891666 0.0021455795385380136 0.017807200123088847 0.01101210908282467\n",
      "val_loss :  0.0021041167292780443 0.008951234004652017 0.019792926680369704 0.028196753459233864\n",
      "epoch :  35 ,train_loss :  0.03244480571050974 ,valid_loss :  0.059045031191963776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 37/40 [5:07:08<24:53, 497.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.37995183855397224 valid_num :  401\n",
      "valid_iou :  0.38031931724981144 valid_num :  402\n",
      "valid_recall :  0.3863013698630137\n",
      "valid_precision :  0.32790697674418606\n",
      "===================LOSS========================\n",
      "loss :  0.0014705522391800783 0.002112492648284444 0.017961755415244824 0.011075250917938291\n",
      "val_loss :  0.00207172757740516 0.007995911444738215 0.01909578134141424 0.023462964733149492\n",
      "epoch :  36 ,train_loss :  0.03262005119970376 ,valid_loss :  0.05262638555437911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 38/40 [5:15:25<16:35, 497.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.3976303658736627 valid_num :  328\n",
      "valid_iou :  0.3980229084349093 valid_num :  329\n",
      "valid_recall :  0.3726027397260274\n",
      "valid_precision :  0.38636363636363635\n",
      "===================LOSS========================\n",
      "loss :  0.00146420584524009 0.0020656668671915988 0.018172679008405388 0.011055012664763471\n",
      "val_loss :  0.0020434807086655614 0.008149026863404787 0.019341153439645674 0.024385396719855422\n",
      "epoch :  37 ,train_loss :  0.0327575644855373 ,valid_loss :  0.05391905781831227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 39/40 [5:23:43<08:17, 497.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.35067027255421923 valid_num :  575\n",
      "valid_iou :  0.3509873907327379 valid_num :  576\n",
      "valid_recall :  0.5095890410958904\n",
      "valid_precision :  0.2985553772070626\n",
      "===================LOSS========================\n",
      "loss :  0.0014596985856316276 0.0020340536003881585 0.018490056919276344 0.0111088158636763\n",
      "val_loss :  0.0020057677072198954 0.007522015779863531 0.018650407793329042 0.021689930382896874\n",
      "epoch :  38 ,train_loss :  0.033092625053291934 ,valid_loss :  0.04986812141450012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [5:32:01<00:00, 498.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================ROI========================\n",
      "roi_over_0.5 0.43355654549876893 valid_num :  238\n",
      "valid_iou :  0.43475571441880184 valid_num :  239\n",
      "valid_recall :  0.2958904109589041\n",
      "valid_precision :  0.42023346303501946\n",
      "===================LOSS========================\n",
      "loss :  0.0014531272534220089 0.0019522623054362613 0.018206807144995882 0.01073183417334758\n",
      "val_loss :  0.0020664807046106193 0.008547237569776675 0.019651335664093494 0.026849986327921644\n",
      "epoch :  39 ,train_loss :  0.03234403091265219 ,valid_loss :  0.05711503998906005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(),  lr=0.0001, momentum=0.9)   # optimize all cnn parameters\n",
    "# torch.optim.Adam(model.parameters(), lr=1e-4, betas = (0.9, 0.999), weight_decay=5e-4)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas = (0.9, 0.999), weight_decay=5e-4)\n",
    "optimizer = torch.optim.SGD(model.parameters(),  lr=lr, momentum=0.9, weight_decay=0.0005)   # optimize all cnn parameters\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=1,gamma=0.95)\n",
    "# Freeze_Epoch = 50\n",
    "Unfreeze_Epoch = epoch\n",
    "best_valid_loss_avg = np.inf\n",
    "\n",
    "# Unfreezed training and validating\n",
    "\n",
    "print('start training (unfreeze ResNet50)')\n",
    "\n",
    "for epoch in tqdm(range(Unfreeze_Epoch)):\n",
    "#     total_loss = np.array([])\n",
    "    rpn_loc_loss = []\n",
    "    rpn_cls_loss = []\n",
    "    roi_loc_loss = []\n",
    "    roi_cls_loss = []\n",
    "    val_rpn_loc_loss = []\n",
    "    val_rpn_cls_loss = []\n",
    "    val_roi_loc_loss = []\n",
    "    val_roi_cls_loss = []\n",
    "#     val_toal_loss = np.array([])\n",
    "\n",
    "    trainlosslist = []\n",
    "    validlosslist = []\n",
    "#     loss_weight = [100,1,100,10]\n",
    "    \n",
    "    rpn_pos_per_batch = []\n",
    "    rpn_neg_per_batch = []\n",
    "    val_rpn_pos_per_batch = []\n",
    "    val_rpn_neg_per_batch = []\n",
    "\n",
    "    # train\n",
    "    model.train()\n",
    "    for step, (imgs, bboxes, labels) in enumerate(train_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            bboxes = bboxes.cuda()\n",
    "            labels = labels.cuda()\n",
    "        targets = []\n",
    "        mode = 'train'\n",
    "        for i in range(imgs.shape[0]):\n",
    "            bbox = bboxes[i]\n",
    "            label = labels[i]\n",
    "            try:\n",
    "                label_num = torch.nonzero(label == 0)[0][0]\n",
    "            except:\n",
    "                label_num = label.shape[0]\n",
    "            label = label[:label_num]\n",
    "            bbox = bbox[:label_num]\n",
    "            d = {}\n",
    "            d['boxes'] = bbox\n",
    "            d['labels'] = label\n",
    "            targets.append(d)\n",
    "        output = model(imgs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        losses = sum(loss for loss in output.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        rpn_loc_loss.append(output['loss_rpn_box_reg'].item())\n",
    "        rpn_cls_loss.append(output['loss_objectness'].item())\n",
    "        roi_loc_loss.append(output['loss_box_reg'].item())\n",
    "        roi_cls_loss.append(output['loss_classifier'].item())\n",
    "        trainlosslist.append(losses.item())\n",
    "#         op_losses = output['loss_rpn_box_reg']*1 + output['loss_objectness']*1 + output['loss_box_reg']*1 + output['loss_classifier']*1\n",
    "#         print('losses', losses, op_losses)\n",
    "\n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, bboxes, labels) in enumerate(valid_dataloader):\n",
    "            if torch.cuda.is_available():\n",
    "                imgs = imgs.cuda()\n",
    "                bboxes = bboxes.cuda()\n",
    "                labels = labels.cuda()\n",
    "            targets = []\n",
    "            mode = 'valid'\n",
    "            for i in range(imgs.shape[0]):\n",
    "                bbox = bboxes[i]\n",
    "                label = labels[i]\n",
    "                try:\n",
    "                    label_num = torch.nonzero(label == 0)[0][0]\n",
    "                except:\n",
    "                    label_num = label.shape[0]\n",
    "                label = label[:label_num]\n",
    "                bbox = bbox[:label_num]\n",
    "                d = {}\n",
    "                d['boxes'] = bbox\n",
    "                d['labels'] = label\n",
    "                targets.append(d)    \n",
    "            output = model(imgs, targets) \n",
    "            losses = sum(loss for loss in output.values())\n",
    "            val_rpn_loc_loss.append(output['loss_rpn_box_reg'].item())\n",
    "            val_rpn_cls_loss.append(output['loss_objectness'].item())\n",
    "            val_roi_loc_loss.append(output['loss_box_reg'].item())\n",
    "            val_roi_cls_loss.append(output['loss_classifier'].item())\n",
    "            validlosslist.append(losses.item())\n",
    "#             op_losses = output['loss_rpn_box_reg']*1 + output['loss_objectness']*1 + output['loss_box_reg']*1 + output['loss_classifier']*1\n",
    "#             print('losses', losses, op_losses)\n",
    "    # validate iou\n",
    "    model.eval()\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    total_boxes = 0\n",
    "    iou_array = np.array([])\n",
    "    valid_iou_array = np.array([])\n",
    "    for step, (imgs, bboxes, labels) in enumerate(valid_iou_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            bboxes = bboxes.cuda()\n",
    "            labels = labels.cuda()\n",
    "        bbox, label = 0, 0\n",
    "        mode = 'valid'\n",
    "        for i in range(imgs.shape[0]):\n",
    "            bbox = bboxes[i]\n",
    "            label = labels[i]\n",
    "            try:\n",
    "                label_num = torch.nonzero(label == 0)[0][0]\n",
    "            except:\n",
    "                label_num = label.shape[0]\n",
    "            label = label[:label_num]\n",
    "            bbox = bbox[:label_num]\n",
    "        output = model(imgs)\n",
    "        total_boxes += bbox.shape[0]\n",
    "        indices = torch.where(output[0]['scores'] > 0.5)[0]\n",
    "        if indices.shape[0] > 0:\n",
    "            if label.shape[0] > 0:\n",
    "                ious = bbox_iou(output[0]['boxes'][indices].cpu().detach().numpy(), bbox.cpu().numpy())\n",
    "                max_ious = np.max(ious, axis=1)\n",
    "#                 max_ious_index = np.argmax(ious, axis=1)\n",
    "#                 unique_max_ious_index = torch.unique(max_ious_index)\n",
    "#                 print('unique', len(unique_max_ious_index) == len(max_ious_index))\n",
    "                true_positive_index = np.where(max_ious > 0.5)[0]\n",
    "                iou_array = np.append(iou_array, max_ious)\n",
    "                valid_iou_array = np.append(iou_array, max_ious[true_positive_index])\n",
    "                true_pos += true_positive_index.shape[0]\n",
    "                false_pos += (indices.shape[0] - true_positive_index.shape[0])\n",
    "            else :\n",
    "                false_pos += indices.shape[0]\n",
    "#         else :\n",
    "#             if label.shape[0] > 0:\n",
    "#                 false_neg += 1\n",
    "#             else :\n",
    "#                 true_neg += 1\n",
    "\n",
    "    \n",
    "    train_loss_avg = np.mean(trainlosslist)\n",
    "    rpn_loc_loss_avg = np.mean(rpn_loc_loss)\n",
    "    rpn_cls_loss_avg = np.mean(rpn_cls_loss)\n",
    "    roi_loc_loss_avg = np.mean(roi_loc_loss)\n",
    "    roi_cls_loss_avg = np.mean(roi_cls_loss)\n",
    "    valid_loss_avg = np.mean(validlosslist)\n",
    "    val_rpn_loc_loss_avg = np.mean(val_rpn_loc_loss)\n",
    "    val_rpn_cls_loss_avg = np.mean(val_rpn_cls_loss)\n",
    "    val_roi_loc_loss_avg = np.mean(val_roi_loc_loss)\n",
    "    val_roi_cls_loss_avg = np.mean(val_roi_cls_loss)\n",
    "\n",
    "#     print('===================RPN========================')\n",
    "#     print('rpn_pos_per_batch', np.mean(rpn_pos_per_batch), len(rpn_pos_per_batch))\n",
    "#     print('rpn_neg_per_batch', np.mean(rpn_neg_per_batch), len(rpn_neg_per_batch))\n",
    "#     print('val_rpn_pos_per_batch', np.mean(val_rpn_pos_per_batch), len(val_rpn_pos_per_batch))\n",
    "#     print('val_rpn_neg_per_batch', np.mean(val_rpn_neg_per_batch), len(val_rpn_neg_per_batch))\n",
    "    \n",
    "    print('===================ROI========================')\n",
    "    print('roi_over_0.5', np.mean(iou_array), 'valid_num : ', iou_array.size )\n",
    "    print('valid_iou : ', np.mean(valid_iou_array), 'valid_num : ', valid_iou_array.size)\n",
    "    try:\n",
    "        print('valid_recall : ', true_pos/total_boxes)\n",
    "    except:\n",
    "        print('valid_recall : ', 0)\n",
    "    try:\n",
    "        print('valid_precision : ', true_pos/(true_pos+false_pos))\n",
    "    except:\n",
    "        print('valid_precision : ', 0)\n",
    "    \n",
    "    print('===================LOSS========================')\n",
    "    print('loss : ', rpn_loc_loss_avg, rpn_cls_loss_avg, roi_loc_loss_avg, roi_cls_loss_avg)\n",
    "    print('val_loss : ', val_rpn_loc_loss_avg, val_rpn_cls_loss_avg, val_roi_loc_loss_avg, val_roi_cls_loss_avg)\n",
    "    print('epoch : ', epoch, ',train_loss : ',train_loss_avg, ',valid_loss : ', valid_loss_avg)\n",
    "    # wandb.log({\"EPOCHS\":epoch, \"Train Loss\":train_loss_avg, \"Valid Loss\":valid_loss_avg}) \n",
    "    if valid_loss_avg < best_valid_loss_avg :\n",
    "        best_valid_loss_avg = valid_loss_avg\n",
    "        print('saving model weight') \n",
    "        torch.save(model.state_dict(), '/kaggle/working/weight.pt')\n",
    "    lr_scheduler.step()\n",
    "# wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555cf96d",
   "metadata": {
    "papermill": {
     "duration": 0.051818,
     "end_time": "2023-06-04T09:41:35.142359",
     "exception": false,
     "start_time": "2023-06-04T09:41:35.090541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20003.420504,
   "end_time": "2023-06-04T09:41:37.881115",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-04T04:08:14.460611",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
