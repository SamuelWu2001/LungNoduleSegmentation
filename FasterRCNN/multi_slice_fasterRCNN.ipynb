{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d346ca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:04:20.464880Z",
     "iopub.status.busy": "2023-06-03T18:04:20.463847Z",
     "iopub.status.idle": "2023-06-03T18:04:23.605032Z",
     "shell.execute_reply": "2023-06-03T18:04:23.604152Z"
    },
    "id": "vNOZbkjDREXX",
    "papermill": {
     "duration": 3.155602,
     "end_time": "2023-06-03T18:04:23.607424",
     "exception": false,
     "start_time": "2023-06-03T18:04:20.451822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7da463ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:04:23.621207Z",
     "iopub.status.busy": "2023-06-03T18:04:23.619578Z",
     "iopub.status.idle": "2023-06-03T18:04:23.673879Z",
     "shell.execute_reply": "2023-06-03T18:04:23.672931Z"
    },
    "id": "bfYa8Bvg7v0f",
    "outputId": "18ff944a-affb-4550-b0fc-a5e0a645f956",
    "papermill": {
     "duration": 0.062751,
     "end_time": "2023-06-03T18:04:23.675949",
     "exception": false,
     "start_time": "2023-06-03T18:04:23.613198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \n",
    "print(\"Use device:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b5e150",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:04:23.691444Z",
     "iopub.status.busy": "2023-06-03T18:04:23.690684Z",
     "iopub.status.idle": "2023-06-03T18:04:23.703513Z",
     "shell.execute_reply": "2023-06-03T18:04:23.702149Z"
    },
    "papermill": {
     "duration": 0.025276,
     "end_time": "2023-06-03T18:04:23.706807",
     "exception": false,
     "start_time": "2023-06-03T18:04:23.681531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "lr = 0.001\n",
    "pretrain = False\n",
    "mode = 'train'\n",
    "epoch = 20\n",
    "pid_range = [251,401]\n",
    "train_range, valid_range, test_range = [251,351], [351,376], [376,401]\n",
    "num_c = 1\n",
    "no_nodule_patch_use_ratio = 0.05\n",
    "\n",
    "rpn_pos_per_batch = []\n",
    "rpn_neg_per_batch = []\n",
    "val_rpn_pos_per_batch = []\n",
    "val_rpn_neg_per_batch = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e436b",
   "metadata": {
    "id": "O-5x61Vu5ynf",
    "papermill": {
     "duration": 0.016305,
     "end_time": "2023-06-03T18:04:23.730427",
     "exception": false,
     "start_time": "2023-06-03T18:04:23.714122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6fc5bb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:04:23.752162Z",
     "iopub.status.busy": "2023-06-03T18:04:23.751799Z",
     "iopub.status.idle": "2023-06-03T18:04:59.576765Z",
     "shell.execute_reply": "2023-06-03T18:04:59.575241Z"
    },
    "id": "0pbpMDEP5x2y",
    "outputId": "58ba42f5-ae6b-427a-fe3d-95e372ca0eda",
    "papermill": {
     "duration": 35.83713,
     "end_time": "2023-06-03T18:04:59.578668",
     "exception": false,
     "start_time": "2023-06-03T18:04:23.741538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading nodule slices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6185/6185 [00:26<00:00, 230.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading other continuous slices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [00:06<00:00, 30.81it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = '/kaggle/input/lidcidri-250-500-continuous/data_continuous/data_continuous' \n",
    "pkl_path = '/kaggle/input/lidcidri-250-500-continuous' \n",
    "meta = pd.read_csv(f'{data_path}/Meta/meta_info.csv')\n",
    "bbox_file = open(f'{pkl_path}/bbox.pkl', 'rb')\n",
    "bbox_list = pickle.load(bbox_file)\n",
    "all_data = {}\n",
    "\n",
    "print(\"loading nodule slices...\")\n",
    "time.sleep(1)\n",
    "for i in tqdm(range(len(meta.index))):\n",
    "    \n",
    "    pid = meta.iloc[i]['patient_id']\n",
    "    if pid_range[0] <= pid < pid_range[1]:\n",
    "        if pid not in all_data: all_data[pid] = {}\n",
    "\n",
    "        slice = int(meta.iloc[i]['original_image'][-3:])\n",
    "        all_data[pid][slice] = {}\n",
    "        if meta.iloc[i]['is_clean'] == False: # nodule\n",
    "            img = np.load(f'{data_path}/Image/LIDC-IDRI-' + meta.iloc[i]['original_image'][:4]\\\n",
    "                           + '/' + meta.iloc[i]['original_image'] + '.npy') \n",
    "        img = np.clip(img, -1200,1200)\n",
    "        img = torch.Tensor(img)\n",
    "        img = img.to(torch.float32) \n",
    "        min_value = img.min()\n",
    "        max_value = img.max()    \n",
    "\n",
    "        shifted_tensor = img - min_value   \n",
    "        img = shifted_tensor / (max_value - min_value)\n",
    "\n",
    "        all_data[pid][slice][\"img\"] = img\n",
    "        all_data[pid][slice][\"bbox\"] = np.array(bbox_list[i])\n",
    "\n",
    "print(\"loading other continuous slices...\")\n",
    "time.sleep(1)\n",
    "for p in tqdm(os.listdir(f'{data_path}/Image')): # others\n",
    "    pid = int(p[-4:])\n",
    "    if pid_range[0] <= pid < pid_range[1]:\n",
    "        for s in os.listdir(f'{data_path}/Image/{p}'):\n",
    "            slice = int(s[-7:-4])\n",
    "            if slice not in all_data[pid] and (slice+1 in all_data[pid] or slice-1 in all_data[pid]):\n",
    "                all_data[pid][slice] = {}\n",
    "                img = np.load(f'{data_path}/Image/{p}/{s}') \n",
    "                img = np.clip(img, -1200, 1200)\n",
    "                img = torch.Tensor(img)\n",
    "                img = img.to(torch.float32) \n",
    "                min_value = img.min()\n",
    "                max_value = img.max()    \n",
    "\n",
    "                shifted_tensor = img - min_value   \n",
    "                img = shifted_tensor / (max_value - min_value)\n",
    "                all_data[pid][slice][\"img\"] = img\n",
    "                all_data[pid][slice][\"bbox\"] = np.array([[0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec8c206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:04:59.630699Z",
     "iopub.status.busy": "2023-06-03T18:04:59.629262Z",
     "iopub.status.idle": "2023-06-03T18:05:09.066027Z",
     "shell.execute_reply": "2023-06-03T18:05:09.064151Z"
    },
    "papermill": {
     "duration": 9.466193,
     "end_time": "2023-06-03T18:05:09.069664",
     "exception": false,
     "start_time": "2023-06-03T18:04:59.603471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing training/validation/testing patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:04<00:00, 31.76it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"preparing training/validation/testing patches...\")\n",
    "time.sleep(1)\n",
    "train_img, train_bbox, train_label = [], [], []\n",
    "valid_img, valid_bbox, valid_label = [], [], []\n",
    "test_img, test_bbox, test_label = [], [], []\n",
    "\n",
    "for patient in tqdm(all_data.keys()):\n",
    "    slice_list = list(sorted(all_data[patient].keys()))[num_c:-num_c]\n",
    "    for slice in slice_list:\n",
    "        if (all_data[patient][slice][\"bbox\"] != [[0,0,0,0]]).all(): # 挑 nodule 的出來切 patch\n",
    "            slice_concat = range(slice-num_c, slice+num_c+1)\n",
    "            imgs_num_c = np.stack(\\\n",
    "                [all_data[patient][s][\"img\"] for s in slice_concat], axis=0)\n",
    "\n",
    "            # print(patient, slice, all_data[patient][slice][\"bbox\"])\n",
    "            for h in range(0, 512-64, 64):\n",
    "                for w in range(0, 512-64, 64):\n",
    "                    patch_img = imgs_num_c[:, h:h+128, w:w+128]\n",
    "                    patch_bbox = all_data[patient][slice][\"bbox\"] -\\\n",
    "                          np.tile([w,h,w,h], (len(all_data[patient][slice][\"bbox\"]), 1))\n",
    "                    for b_idx, box in enumerate(patch_bbox):\n",
    "                        if ((box[0] < 0 or box[0] >= 127) or (box[1] < 0 or box[1] >= 127))\\\n",
    "                            and ((box[2] <= 0 or box[2] > 127) or (box[3] <= 0 or box[3] > 127)):\n",
    "                            patch_bbox[b_idx] = [0,0,0,0]\n",
    "                        else:\n",
    "                            patch_bbox[b_idx] = np.clip(box, 0, 127)\n",
    "\n",
    "                    use = True\n",
    "                    if all((bbox == [0,0,0,0]).all() for bbox in patch_bbox):\n",
    "                        patch_bbox = [[0,0,0,0]]\n",
    "                        label = torch.zeros(1).type(torch.int64)\n",
    "                        if random.random() >= no_nodule_patch_use_ratio: use = False\n",
    "                    else: \n",
    "                        mask = np.any(patch_bbox != [0,0,0,0], axis=1)\n",
    "                        patch_bbox = patch_bbox[mask]\n",
    "                        label = torch.ones(len(patch_bbox)).type(torch.int64)\n",
    "\n",
    "                    if use == True:\n",
    "                        if train_range[0] <= patient < train_range[1]:\n",
    "                            train_img.append(patch_img)\n",
    "                            train_bbox.append(patch_bbox)\n",
    "                            train_label.append(label)\n",
    "                    if valid_range[0] <= patient < valid_range[1]:\n",
    "                        valid_img.append(patch_img)\n",
    "                        valid_bbox.append(patch_bbox)\n",
    "                        valid_label.append(label)\n",
    "                    elif test_range[0] <= patient < test_range[1]:\n",
    "                        test_img.append(patch_img)\n",
    "                        test_bbox.append(patch_bbox)\n",
    "                        test_label.append(label)\n",
    "\n",
    "train_img = np.array(train_img)\n",
    "valid_img = np.array(valid_img)\n",
    "test_img = np.array(test_img)\n",
    "\n",
    "del all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c55389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:05:09.124344Z",
     "iopub.status.busy": "2023-06-03T18:05:09.123996Z",
     "iopub.status.idle": "2023-06-03T18:05:09.130689Z",
     "shell.execute_reply": "2023-06-03T18:05:09.129791Z"
    },
    "id": "qmfQwsOU4PoW",
    "outputId": "3096783e-0e11-4827-fcae-e3da6991f192",
    "papermill": {
     "duration": 0.036038,
     "end_time": "2023-06-03T18:05:09.132624",
     "exception": false,
     "start_time": "2023-06-03T18:05:09.096586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3910 6076 9800 3909 6076 9800 3911 6076 9800\n"
     ]
    }
   ],
   "source": [
    "print(len(train_img[:-1]), len(valid_img), len(test_img), len(train_bbox[:-2]), len(valid_bbox), len(test_bbox), len(train_label), len(valid_label), len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ddcfc7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:05:09.187884Z",
     "iopub.status.busy": "2023-06-03T18:05:09.186466Z",
     "iopub.status.idle": "2023-06-03T18:05:09.672782Z",
     "shell.execute_reply": "2023-06-03T18:05:09.671534Z"
    },
    "id": "jeglxwZn7rkc",
    "outputId": "15147723-b425-491c-f6a4-7b9da1c437ab",
    "papermill": {
     "duration": 0.517774,
     "end_time": "2023-06-03T18:05:09.676690",
     "exception": false,
     "start_time": "2023-06-03T18:05:09.158916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([8, 3, 128, 128])\n",
      "Bounding boxes shape: torch.Size([8, 2, 4])\n",
      "Labels shape: torch.Size([8, 2]) tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class FasterRCNNDataset(Dataset):\n",
    "    def __init__(self, image_list, bboxes_list, labels_list, transform=None):\n",
    "        self.image_list = image_list\n",
    "        self.bboxes_list = bboxes_list\n",
    "        self.labels_list = labels_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.image_list[idx]\n",
    "        bboxes = self.bboxes_list[idx]\n",
    "        labels = self.labels_list[idx]\n",
    "\n",
    "        image = torch.tensor(image)\n",
    "#         image = torch.unsqueeze(image, 0)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        bboxes = torch.tensor(bboxes)\n",
    "        labels = labels\n",
    "\n",
    "        return image, bboxes, labels\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    image_list = []\n",
    "    bboxes_list = []\n",
    "    labels_list = []\n",
    "    for item in batch:\n",
    "        image_list.append(item[0])\n",
    "        bboxes_list.append(item[1])\n",
    "        labels_list.append(item[2])\n",
    "\n",
    "    # Pad the lists of bounding boxes with -1\n",
    "    max_num_bboxes = max(len(bboxes) for bboxes in bboxes_list)\n",
    "    padded_bboxes_list = []\n",
    "    for bboxes in bboxes_list:\n",
    "        padded_bboxes = torch.cat((bboxes, torch.tensor([[-1, -1, -1, -1]]).expand((max_num_bboxes - len(bboxes)), -1)), dim=0)\n",
    "        padded_bboxes_list.append(padded_bboxes)\n",
    "\n",
    "    # Pad label\n",
    "    max_num_labels = max_num_bboxes\n",
    "    padded_labels_list = []\n",
    "    for labels in labels_list:\n",
    "        padded_labels = torch.cat((labels, torch.zeros(max_num_labels - len(labels)).type(torch.int64)), dim=0)\n",
    "        padded_labels_list.append(padded_labels)\n",
    "    # Convert images, bboxes, and labels to tensors\n",
    "    image_list = torch.stack(image_list)\n",
    "    padded_bboxes_list = torch.stack(padded_bboxes_list)\n",
    "    padded_labels_list = torch.stack(padded_labels_list)\n",
    "\n",
    "    return image_list, padded_bboxes_list, padded_labels_list\n",
    "\n",
    "# transform  = transforms.Resize([600,600]) \n",
    "train_dataset = FasterRCNNDataset(train_img, train_bbox, train_label)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "valid_dataset = FasterRCNNDataset(valid_img, valid_bbox, valid_label)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "valid_iou_dataloader = DataLoader(valid_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "test_dataset = FasterRCNNDataset(test_img, test_bbox, test_label)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "for images, bboxes, labels in train_dataloader:\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Bounding boxes shape:\", bboxes.shape)\n",
    "    print(\"Labels shape:\", labels.shape, labels)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b392ae8",
   "metadata": {
    "id": "KRO5QpJKx2cs",
    "papermill": {
     "duration": 0.026115,
     "end_time": "2023-06-03T18:05:09.745673",
     "exception": false,
     "start_time": "2023-06-03T18:05:09.719558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca750cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:05:09.799156Z",
     "iopub.status.busy": "2023-06-03T18:05:09.798794Z",
     "iopub.status.idle": "2023-06-03T18:05:09.810873Z",
     "shell.execute_reply": "2023-06-03T18:05:09.810045Z"
    },
    "papermill": {
     "duration": 0.041295,
     "end_time": "2023-06-03T18:05:09.812983",
     "exception": false,
     "start_time": "2023-06-03T18:05:09.771688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "def custom_rpn_cls_loss(logits, labels, num_hard=2):\n",
    "        \n",
    "    classify_loss = nn.BCELoss()\n",
    "    probs = torch.sigmoid(logits)[:] #.view(-1, 1)\n",
    "    pos_idcs = labels[:] == 1\n",
    "    pos_prob = probs[pos_idcs]\n",
    "    pos_labels = labels[pos_idcs]\n",
    "\n",
    "    neg_idcs = labels[:] == 0\n",
    "    neg_prob = probs[neg_idcs]\n",
    "    neg_labels = labels[neg_idcs]\n",
    "    p_indices = torch.where(labels == 1)\n",
    "    n_indices = torch.where(labels == 0)\n",
    "#     print('NUM', p_indices[0].shape, n_indices[0].shape)\n",
    "    if mode == 'valid': \n",
    "        num_hard=1000000000\n",
    "        val_rpn_pos_per_batch.append(p_indices[0].shape)\n",
    "        val_rpn_neg_per_batch.append(n_indices[0].shape) \n",
    "    else :\n",
    "        rpn_pos_per_batch.append(p_indices[0].shape)\n",
    "        rpn_neg_per_batch.append(n_indices[0].shape)\n",
    "    \n",
    "    if num_hard > 0:\n",
    "        neg_prob, neg_labels = OHEM(neg_prob, neg_labels, num_hard * len(pos_prob))\n",
    "\n",
    "    pos_correct = 0\n",
    "    pos_total = 0\n",
    "    if len(pos_prob) > 0:\n",
    "        cls_loss = 0.5 * classify_loss(\n",
    "            pos_prob, pos_labels.float()) + 0.5 * classify_loss(\n",
    "            neg_prob, neg_labels.float())\n",
    "        pos_correct = (pos_prob >= 0.5).sum()\n",
    "        pos_total = len(pos_prob)\n",
    "    else:\n",
    "        cls_loss = 0.5 * classify_loss(\n",
    "            neg_prob, neg_labels.float())\n",
    "\n",
    "\n",
    "    neg_correct = (neg_prob < 0.5).sum()\n",
    "    neg_total = len(neg_prob)\n",
    "    return cls_loss #pos_correct, pos_total, neg_correct, neg_total\n",
    "\n",
    "\n",
    "def OHEM(neg_output, neg_labels, num_hard):\n",
    "    _, idcs = torch.topk(neg_output, min(num_hard, len(neg_output)))\n",
    "    neg_output = torch.index_select(neg_output, 0, idcs)\n",
    "    neg_labels = torch.index_select(neg_labels, 0, idcs)\n",
    "    return neg_output, neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0895f2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:05:09.866633Z",
     "iopub.status.busy": "2023-06-03T18:05:09.866358Z",
     "iopub.status.idle": "2023-06-03T18:05:09.878749Z",
     "shell.execute_reply": "2023-06-03T18:05:09.877897Z"
    },
    "papermill": {
     "duration": 0.042045,
     "end_time": "2023-06-03T18:05:09.880977",
     "exception": false,
     "start_time": "2023-06-03T18:05:09.838932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_rcnn_loss(class_logits, box_regression, labels, regression_targets):\n",
    "    # type: (Tensor, Tensor, List[Tensor], List[Tensor]) -> Tuple[Tensor, Tensor]\n",
    "    \"\"\"\n",
    "    Computes the loss for Faster R-CNN.\n",
    "\n",
    "    Args:\n",
    "        class_logits (Tensor)\n",
    "        box_regression (Tensor)\n",
    "        labels (list[BoxList])\n",
    "        regression_targets (Tensor)\n",
    "\n",
    "    Returns:\n",
    "        classification_loss (Tensor)\n",
    "        box_loss (Tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    regression_targets = torch.cat(regression_targets, dim=0)\n",
    "    \n",
    "    batch_size, num_class = class_logits.shape[:2]\n",
    "#     print('Samuel')\n",
    "    weight = torch.ones(num_class)\n",
    "    if torch.cuda.is_available():\n",
    "        weight = weight.cuda()\n",
    "#     print('Samuel222')\n",
    "    total = len(labels)\n",
    "#     print('Samuel3333')\n",
    "    for i in range(num_class):\n",
    "        num_pos = float((labels == i).sum())\n",
    "        num_pos = max(num_pos, 1)\n",
    "        weight[i] = total / num_pos\n",
    "    \n",
    "#     print('Samuel444')\n",
    "    weight = weight / weight.sum()\n",
    "#     print('Samuel5555')\n",
    "\n",
    "    classification_loss = F.cross_entropy(class_logits, labels, weight=weight)\n",
    "\n",
    "    # get indices that correspond to the regression targets for\n",
    "    # the corresponding ground truth labels, to be used with\n",
    "    # advanced indexing\n",
    "    sampled_pos_inds_subset = torch.where(labels > 0)[0]\n",
    "    labels_pos = labels[sampled_pos_inds_subset]\n",
    "    N, num_classes = class_logits.shape\n",
    "    box_regression = box_regression.reshape(N, box_regression.size(-1) // 4, 4)\n",
    "\n",
    "    box_loss = F.smooth_l1_loss(\n",
    "        box_regression[sampled_pos_inds_subset, labels_pos],\n",
    "        regression_targets[sampled_pos_inds_subset],\n",
    "        beta=1 / 9,\n",
    "        reduction=\"sum\",\n",
    "    )\n",
    "    box_loss = box_loss / labels.numel()\n",
    "\n",
    "    return classification_loss, box_loss\n",
    "\n",
    "def fastrcnn_loss(class_logits, box_regression, labels, regression_targets):\n",
    "    # type: (Tensor, Tensor, List[Tensor], List[Tensor]) -> Tuple[Tensor, Tensor]\n",
    "    \"\"\"\n",
    "    Computes the loss for Faster R-CNN.\n",
    "\n",
    "    Args:\n",
    "        class_logits (Tensor)\n",
    "        box_regression (Tensor)\n",
    "        labels (list[BoxList])\n",
    "        regression_targets (Tensor)\n",
    "\n",
    "    Returns:\n",
    "        classification_loss (Tensor)\n",
    "        box_loss (Tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    regression_targets = torch.cat(regression_targets, dim=0)\n",
    "\n",
    "    classification_loss = F.cross_entropy(class_logits, labels)\n",
    "\n",
    "    # get indices that correspond to the regression targets for\n",
    "    # the corresponding ground truth labels, to be used with\n",
    "    # advanced indexing\n",
    "    sampled_pos_inds_subset = torch.where(labels > 0)[0]\n",
    "    labels_pos = labels[sampled_pos_inds_subset]\n",
    "    N, num_classes = class_logits.shape\n",
    "    box_regression = box_regression.reshape(N, box_regression.size(-1) // 4, 4)\n",
    "\n",
    "    box_loss = F.smooth_l1_loss(\n",
    "        box_regression[sampled_pos_inds_subset, labels_pos],\n",
    "        regression_targets[sampled_pos_inds_subset],\n",
    "        beta=1 / 9,\n",
    "        reduction=\"sum\",\n",
    "    )\n",
    "    box_loss = box_loss / labels.numel()\n",
    "\n",
    "    return classification_loss, box_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "919cce81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:05:09.934340Z",
     "iopub.status.busy": "2023-06-03T18:05:09.934016Z",
     "iopub.status.idle": "2023-06-03T18:05:09.963530Z",
     "shell.execute_reply": "2023-06-03T18:05:09.962741Z"
    },
    "papermill": {
     "duration": 0.058731,
     "end_time": "2023-06-03T18:05:09.965551",
     "exception": false,
     "start_time": "2023-06-03T18:05:09.906820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models.detection.roi_heads import RoIHeads\n",
    "from torchvision.models.detection import _utils as det_utils\n",
    "\n",
    "class CustomRoIHead(RoIHeads):\n",
    "    __annotations__ = {\n",
    "        \"box_coder\": det_utils.BoxCoder,\n",
    "        \"proposal_matcher\": det_utils.Matcher,\n",
    "        \"fg_bg_sampler\": det_utils.BalancedPositiveNegativeSampler,\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        box_roi_pool,\n",
    "        box_head,\n",
    "        box_predictor,\n",
    "        # Faster R-CNN training\n",
    "        fg_iou_thresh,\n",
    "        bg_iou_thresh,\n",
    "        batch_size_per_image,\n",
    "        positive_fraction,\n",
    "        bbox_reg_weights,\n",
    "        # Faster R-CNN inference\n",
    "        score_thresh,\n",
    "        nms_thresh,\n",
    "        detections_per_img,\n",
    "        # Mask\n",
    "        mask_roi_pool=None,\n",
    "        mask_head=None,\n",
    "        mask_predictor=None,\n",
    "        keypoint_roi_pool=None,\n",
    "        keypoint_head=None,\n",
    "        keypoint_predictor=None,\n",
    "    ):\n",
    "        super().__init__(box_roi_pool,\n",
    "        box_head,\n",
    "        box_predictor,\n",
    "        # Faster R-CNN training\n",
    "        fg_iou_thresh,\n",
    "        bg_iou_thresh,\n",
    "        batch_size_per_image,\n",
    "        positive_fraction,\n",
    "        bbox_reg_weights,\n",
    "        # Faster R-CNN inference\n",
    "        score_thresh,\n",
    "        nms_thresh,\n",
    "        detections_per_img,\n",
    "        # Mask\n",
    "        mask_roi_pool,\n",
    "        mask_head,\n",
    "        mask_predictor,\n",
    "        keypoint_roi_pool,\n",
    "        keypoint_head,\n",
    "        keypoint_predictor,\n",
    "        )\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        features,  # type: Dict[str, Tensor]\n",
    "        proposals,  # type: List[Tensor]\n",
    "        image_shapes,  # type: List[Tuple[int, int]]\n",
    "        targets=None,  # type: Optional[List[Dict[str, Tensor]]]\n",
    "    ):\n",
    "        # type: (...) -> Tuple[List[Dict[str, Tensor]], Dict[str, Tensor]]\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features (List[Tensor])\n",
    "            proposals (List[Tensor[N, 4]])\n",
    "            image_shapes (List[Tuple[H, W]])\n",
    "            targets (List[Dict])\n",
    "        \"\"\"\n",
    "        if targets is not None:\n",
    "            for t in targets:\n",
    "                # TODO: https://github.com/pytorch/pytorch/issues/26731\n",
    "                floating_point_types = (torch.float, torch.double, torch.half)\n",
    "                if not t[\"boxes\"].dtype in floating_point_types:\n",
    "                    raise TypeError(f\"target boxes must of float type, instead got {t['boxes'].dtype}\")\n",
    "                if not t[\"labels\"].dtype == torch.int64:\n",
    "                    raise TypeError(f\"target labels must of int64 type, instead got {t['labels'].dtype}\")\n",
    "                if self.has_keypoint():\n",
    "                    if not t[\"keypoints\"].dtype == torch.float32:\n",
    "                        raise TypeError(f\"target keypoints must of float type, instead got {t['keypoints'].dtype}\")\n",
    "\n",
    "        if self.training:\n",
    "            proposals, matched_idxs, labels, regression_targets = self.select_training_samples(proposals, targets)\n",
    "        else:\n",
    "            labels = None\n",
    "            regression_targets = None\n",
    "            matched_idxs = None\n",
    "\n",
    "        box_features = self.box_roi_pool(features, proposals, image_shapes)\n",
    "        box_features = self.box_head(box_features)\n",
    "        class_logits, box_regression = self.box_predictor(box_features)\n",
    "\n",
    "        result: List[Dict[str, torch.Tensor]] = []\n",
    "        losses = {}\n",
    "        if self.training:\n",
    "            if labels is None:\n",
    "                raise ValueError(\"labels cannot be None\")\n",
    "            if regression_targets is None:\n",
    "                raise ValueError(\"regression_targets cannot be None\")\n",
    "            loss_classifier, loss_box_reg = custom_rcnn_loss(class_logits, box_regression, labels, regression_targets)\n",
    "            losses = {\"loss_classifier\": loss_classifier, \"loss_box_reg\": loss_box_reg}\n",
    "        else:\n",
    "            boxes, scores, labels = self.postprocess_detections(class_logits, box_regression, proposals, image_shapes)\n",
    "            num_images = len(boxes)\n",
    "            for i in range(num_images):\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"boxes\": boxes[i],\n",
    "                        \"labels\": labels[i],\n",
    "                        \"scores\": scores[i],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        if self.has_mask():\n",
    "            mask_proposals = [p[\"boxes\"] for p in result]\n",
    "            if self.training:\n",
    "                if matched_idxs is None:\n",
    "                    raise ValueError(\"if in training, matched_idxs should not be None\")\n",
    "\n",
    "                # during training, only focus on positive boxes\n",
    "                num_images = len(proposals)\n",
    "                mask_proposals = []\n",
    "                pos_matched_idxs = []\n",
    "                for img_id in range(num_images):\n",
    "                    pos = torch.where(labels[img_id] > 0)[0]\n",
    "                    mask_proposals.append(proposals[img_id][pos])\n",
    "                    pos_matched_idxs.append(matched_idxs[img_id][pos])\n",
    "            else:\n",
    "                pos_matched_idxs = None\n",
    "\n",
    "            if self.mask_roi_pool is not None:\n",
    "                mask_features = self.mask_roi_pool(features, mask_proposals, image_shapes)\n",
    "                mask_features = self.mask_head(mask_features)\n",
    "                mask_logits = self.mask_predictor(mask_features)\n",
    "            else:\n",
    "                raise Exception(\"Expected mask_roi_pool to be not None\")\n",
    "\n",
    "            loss_mask = {}\n",
    "            if self.training:\n",
    "                if targets is None or pos_matched_idxs is None or mask_logits is None:\n",
    "                    raise ValueError(\"targets, pos_matched_idxs, mask_logits cannot be None when training\")\n",
    "\n",
    "                gt_masks = [t[\"masks\"] for t in targets]\n",
    "                gt_labels = [t[\"labels\"] for t in targets]\n",
    "                rcnn_loss_mask = maskrcnn_loss(mask_logits, mask_proposals, gt_masks, gt_labels, pos_matched_idxs)\n",
    "                loss_mask = {\"loss_mask\": rcnn_loss_mask}\n",
    "            else:\n",
    "                labels = [r[\"labels\"] for r in result]\n",
    "                masks_probs = maskrcnn_inference(mask_logits, labels)\n",
    "                for mask_prob, r in zip(masks_probs, result):\n",
    "                    r[\"masks\"] = mask_prob\n",
    "\n",
    "            losses.update(loss_mask)\n",
    "\n",
    "        # keep none checks in if conditional so torchscript will conditionally\n",
    "        # compile each branch\n",
    "        if (\n",
    "            self.keypoint_roi_pool is not None\n",
    "            and self.keypoint_head is not None\n",
    "            and self.keypoint_predictor is not None\n",
    "        ):\n",
    "            keypoint_proposals = [p[\"boxes\"] for p in result]\n",
    "            if self.training:\n",
    "                # during training, only focus on positive boxes\n",
    "                num_images = len(proposals)\n",
    "                keypoint_proposals = []\n",
    "                pos_matched_idxs = []\n",
    "                if matched_idxs is None:\n",
    "                    raise ValueError(\"if in trainning, matched_idxs should not be None\")\n",
    "\n",
    "                for img_id in range(num_images):\n",
    "                    pos = torch.where(labels[img_id] > 0)[0]\n",
    "                    keypoint_proposals.append(proposals[img_id][pos])\n",
    "                    pos_matched_idxs.append(matched_idxs[img_id][pos])\n",
    "            else:\n",
    "                pos_matched_idxs = None\n",
    "\n",
    "            keypoint_features = self.keypoint_roi_pool(features, keypoint_proposals, image_shapes)\n",
    "            keypoint_features = self.keypoint_head(keypoint_features)\n",
    "            keypoint_logits = self.keypoint_predictor(keypoint_features)\n",
    "\n",
    "            loss_keypoint = {}\n",
    "            if self.training:\n",
    "                if targets is None or pos_matched_idxs is None:\n",
    "                    raise ValueError(\"both targets and pos_matched_idxs should not be None when in training mode\")\n",
    "\n",
    "                gt_keypoints = [t[\"keypoints\"] for t in targets]\n",
    "                rcnn_loss_keypoint = keypointrcnn_loss(\n",
    "                    keypoint_logits, keypoint_proposals, gt_keypoints, pos_matched_idxs\n",
    "                )\n",
    "                loss_keypoint = {\"loss_keypoint\": rcnn_loss_keypoint}\n",
    "            else:\n",
    "                if keypoint_logits is None or keypoint_proposals is None:\n",
    "                    raise ValueError(\n",
    "                        \"both keypoint_logits and keypoint_proposals should not be None when not in training mode\"\n",
    "                    )\n",
    "\n",
    "                keypoints_probs, kp_scores = keypointrcnn_inference(keypoint_logits, keypoint_proposals)\n",
    "                for keypoint_prob, kps, r in zip(keypoints_probs, kp_scores, result):\n",
    "                    r[\"keypoints\"] = keypoint_prob\n",
    "                    r[\"keypoints_scores\"] = kps\n",
    "            losses.update(loss_keypoint)\n",
    "\n",
    "        return result, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f0a797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:05:10.019303Z",
     "iopub.status.busy": "2023-06-03T18:05:10.019009Z",
     "iopub.status.idle": "2023-06-03T18:05:11.295179Z",
     "shell.execute_reply": "2023-06-03T18:05:11.294145Z"
    },
    "id": "bEnRtOTOl6e1",
    "outputId": "e3beebee-dc5f-4b9c-8b0d-a266e2900d45",
    "papermill": {
     "duration": 1.306387,
     "end_time": "2023-06-03T18:05:11.297925",
     "exception": false,
     "start_time": "2023-06-03T18:05:09.991538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 207MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "from torch import Tensor\n",
    "from typing import Tuple, List, Dict\n",
    "import torchvision.ops as ops\n",
    "from torchvision.models.detection.faster_rcnn import TwoMLPHead\n",
    "\n",
    "# model = models.detection.fasterrcnn_resnet50_fpn(pretrained=pretrain)\n",
    "model = models.detection.fasterrcnn_resnet50_fpn()\n",
    "\n",
    "model.transform = GeneralizedRCNNTransform(128,128,[0, 0, 0], [1, 1, 1])\n",
    "model.backbone.body.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
    "\n",
    "\n",
    "# rpn replace \n",
    "from torchvision.models.detection.rpn import RegionProposalNetwork\n",
    "from torchvision.models.detection.rpn import RPNHead\n",
    "class CustomRPN(RegionProposalNetwork):\n",
    "    def __init__(\n",
    "        self,\n",
    "        anchor_generator: AnchorGenerator,\n",
    "        head: nn.Module,\n",
    "        # Faster-RCNN Training\n",
    "        fg_iou_thresh: float,\n",
    "        bg_iou_thresh: float,\n",
    "        batch_size_per_image: int,\n",
    "        positive_fraction: float,\n",
    "        # Faster-RCNN Inference\n",
    "        pre_nms_top_n: Dict[str, int],\n",
    "        post_nms_top_n: Dict[str, int],\n",
    "        nms_thresh: float,\n",
    "        score_thresh: float = 0.0,\n",
    "    ) -> None:\n",
    "        super().__init__(anchor_generator, head, fg_iou_thresh, bg_iou_thresh, batch_size_per_image, positive_fraction, pre_nms_top_n, post_nms_top_n, nms_thresh, score_thresh)\n",
    "\n",
    "    def compute_loss(\n",
    "        self, objectness: Tensor, pred_bbox_deltas: Tensor, labels: List[Tensor], regression_targets: List[Tensor]\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            objectness (Tensor)\n",
    "            pred_bbox_deltas (Tensor)\n",
    "            labels (List[Tensor])\n",
    "            regression_targets (List[Tensor])\n",
    "\n",
    "        Returns:\n",
    "            objectness_loss (Tensor)\n",
    "            box_loss (Tensor)\n",
    "        \"\"\"\n",
    "\n",
    "        sampled_pos_inds, sampled_neg_inds = self.fg_bg_sampler(labels)\n",
    "#         print('sampled_pos_inds', type(sampled_pos_inds[0]), sampled_pos_inds[0].shape)\n",
    "#         print('sampled_neg_inds', type(sampled_neg_inds[0]), sampled_neg_inds[0].shape)\n",
    "        \n",
    "        sampled_pos_inds = torch.where(torch.cat(sampled_pos_inds, dim=0))[0]\n",
    "        sampled_neg_inds = torch.where(torch.cat(sampled_neg_inds, dim=0))[0]\n",
    "\n",
    "        sampled_inds = torch.cat([sampled_pos_inds, sampled_neg_inds], dim=0)\n",
    "\n",
    "        objectness = objectness.flatten()\n",
    "\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "        regression_targets = torch.cat(regression_targets, dim=0)\n",
    "\n",
    "        box_loss = F.smooth_l1_loss(\n",
    "            pred_bbox_deltas[sampled_pos_inds],\n",
    "            regression_targets[sampled_pos_inds],\n",
    "            beta=1 / 9,\n",
    "            reduction=\"sum\",\n",
    "        ) / (sampled_inds.numel())\n",
    "        objectness_loss = custom_rpn_cls_loss(objectness[sampled_inds], labels[sampled_inds]) # F.binary_cross_entropy_with_logits\n",
    "\n",
    "        return objectness_loss, box_loss\n",
    "aspect_ratios = [(0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0)]\n",
    "sizes = ((4,), (8,), (16,), (32,), (64,)) \n",
    "model.rpn =  CustomRPN(AnchorGenerator(sizes=sizes, aspect_ratios=aspect_ratios), RPNHead(256, 15), 0.7, 0.3, 256, 0.5, {'training': 12000, 'testing': 3000}, {'training': 600, 'testing': 300}, 0.7)\n",
    "\n",
    "in_feature = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# model.roi_heads.box_predictor =FastRCNNPredictor(in_feature, 2)\n",
    "model.roi_heads = CustomRoIHead(ops.MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2),\n",
    "                                TwoMLPHead(12544, 1024),\n",
    "                                FastRCNNPredictor(in_feature, 2),\n",
    "                                fg_iou_thresh = 0.5,\n",
    "                                bg_iou_thresh = 0.5,\n",
    "                                score_thresh = 0.05,\n",
    "                                nms_thresh = 0.5,\n",
    "                                detections_per_img = 100,\n",
    "                                batch_size_per_image = 512,\n",
    "                                positive_fraction = 0.25,\n",
    "                                bbox_reg_weights = None,\n",
    "                                )\n",
    "# 'box_roi_pool', 'box_head', 'box_predictor', 'fg_iou_thresh', \n",
    "# 'bg_iou_thresh', 'batch_size_per_image', 'positive_fraction', 'bbox_reg_weights', \n",
    "# 'score_thresh', 'nms_thresh', and 'detections_per_img'\n",
    "\n",
    "# print(model)\n",
    "\n",
    "def bbox_iou(bbox_a, bbox_b):\n",
    "    if bbox_a.shape[1]!=4 or bbox_b.shape[1]!=4:\n",
    "        raise IndexError\n",
    "    tl = np.maximum(bbox_a[:, None, :2], bbox_b[:, :2])\n",
    "    br = np.minimum(bbox_a[:, None, 2:], bbox_b[:, 2:])\n",
    "\n",
    "    area_i = np.prod(br-tl, axis=2) * (tl<br).all(axis=2)\n",
    "    area_a = np.prod(bbox_a[:, 2:] - bbox_a[:, :2], axis=1)\n",
    "    area_b = np.prod(bbox_b[:, 2:] - bbox_b[:, :2], axis=1)\n",
    "\n",
    "    return area_i / (area_a[:, None] + area_b - area_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06be5a0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:05:11.357446Z",
     "iopub.status.busy": "2023-06-03T18:05:11.356622Z",
     "iopub.status.idle": "2023-06-03T18:05:11.365472Z",
     "shell.execute_reply": "2023-06-03T18:05:11.364148Z"
    },
    "id": "XbdoAothzdlA",
    "outputId": "5bdc0bc1-8c91-4d55-e736-84917a059295",
    "papermill": {
     "duration": 0.041239,
     "end_time": "2023-06-03T18:05:11.367543",
     "exception": false,
     "start_time": "2023-06-03T18:05:11.326304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ious [[0.10810811 0.        ]\n",
      " [0.17142857 0.        ]]\n",
      "max_ious <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "ious = bbox_iou(np.array([[1,1,6,6], [5,1,10,6]]), np.array([[4,4,8,8],[9,9,10,10]]))\n",
    "print('ious', ious)\n",
    "max_ious = np.max(ious, axis=1)\n",
    "print('max_ious', type(max_ious))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6074243b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T18:05:11.423757Z",
     "iopub.status.busy": "2023-06-03T18:05:11.423472Z",
     "iopub.status.idle": "2023-06-03T22:13:36.501951Z",
     "shell.execute_reply": "2023-06-03T22:13:36.501057Z"
    },
    "id": "5lNrA0QlQhbT",
    "outputId": "a1fb5465-a17c-4b09-d00f-15a09ff7d715",
    "papermill": {
     "duration": 14905.140291,
     "end_time": "2023-06-03T22:13:36.535264",
     "exception": false,
     "start_time": "2023-06-03T18:05:11.394973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training (unfreeze ResNet50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [12:28<3:56:55, 748.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.027928247863623454 valid_num :  11168\n",
      "valid_recall :  0.9923954372623575\n",
      "valid_precision :  0.09563942836203737\n",
      "===================LOSS========================\n",
      "loss :  0.0029273256861270503 0.7010446590636161 0.001132923849785517 0.26184874890345494\n",
      "val_loss :  0.00030208105449913236 nan 0.00011791440192909202 0.13376822728590157\n",
      "epoch :  0 ,train_loss :  1.368918360010978 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [24:50<3:43:26, 744.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.05479522822959775 valid_num :  4233\n",
      "valid_recall :  0.9486692015209125\n",
      "valid_precision :  0.11980792316926771\n",
      "===================LOSS========================\n",
      "loss :  0.002908095868990246 0.6968342795937583 0.0013662579110573154 0.06545698025848541\n",
      "val_loss :  0.00029985850486283244 nan 8.350736346340987e-05 0.14029982559762796\n",
      "epoch :  1 ,train_loss :  1.1897266381601126 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [37:20<3:31:40, 747.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.04672638686821599 valid_num :  3643\n",
      "valid_recall :  0.9562737642585551\n",
      "valid_precision :  0.11405895691609977\n",
      "===================LOSS========================\n",
      "loss :  0.0029044591232868584 0.6959340912432759 0.001418562167503897 0.05715084321614058\n",
      "val_loss :  0.0002994337758106045 nan 6.504105550525789e-05 0.10801522049525948\n",
      "epoch :  2 ,train_loss :  1.1853870648304135 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [49:42<3:18:39, 744.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.07559498949885131 valid_num :  2367\n",
      "valid_recall :  0.9011406844106464\n",
      "valid_precision :  0.12562947256824808\n",
      "===================LOSS========================\n",
      "loss :  0.0029083583919985645 0.6953530506609895 0.001418531447677349 0.03126670048973982\n",
      "val_loss :  0.00030001181273148274 nan 0.0001303345607933998 0.1476314768805184\n",
      "epoch :  3 ,train_loss :  1.1593087391131738 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [1:02:05<3:06:07, 744.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.056236421118250904 valid_num :  2384\n",
      "valid_recall :  0.903041825095057\n",
      "valid_precision :  0.11585365853658537\n",
      "===================LOSS========================\n",
      "loss :  0.002901593346860791 0.6951632749571147 0.0011017122127620343 0.03197273692679887\n",
      "val_loss :  0.00030028642272315523 nan 0.00011178094330770555 0.14060233186679205\n",
      "epoch :  4 ,train_loss :  1.1274665659922032 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [1:14:26<2:53:22, 743.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.06056689707278333 valid_num :  1925\n",
      "valid_recall :  0.8574144486692015\n",
      "valid_precision :  0.1174785100286533\n",
      "===================LOSS========================\n",
      "loss :  0.002900739431934496 0.6947257923446062 0.0010455321631564353 0.02076391029459232\n",
      "val_loss :  0.0003000105797151551 nan 4.869215593686623e-05 0.14906837604388495\n",
      "epoch :  5 ,train_loss :  1.110116861836798 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [1:26:58<2:41:38, 746.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.06850859400471572 valid_num :  1696\n",
      "valid_recall :  0.8136882129277566\n",
      "valid_precision :  0.1296969696969697\n",
      "===================LOSS========================\n",
      "loss :  0.0028992444172357295 0.6945296632000274 0.0009289623753002143 0.0156265162400509\n",
      "val_loss :  0.00029851796706632165 nan 5.701274909776992e-05 0.18858272139652016\n",
      "epoch :  6 ,train_loss :  1.092976862058074 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [1:39:27<2:29:24, 747.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.10505408668506218 valid_num :  654\n",
      "valid_recall :  0.5627376425855514\n",
      "valid_precision :  0.15171706817016914\n",
      "===================LOSS========================\n",
      "loss :  0.00289664376712288 0.6943861543522778 0.0008090499337694195 0.0141074667943752\n",
      "val_loss :  0.0002999851066832841 nan 8.401928468508027e-05 0.28871850838916685\n",
      "epoch :  7 ,train_loss :  1.0790629901281408 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [1:51:53<2:16:53, 746.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.12082660468501637 valid_num :  571\n",
      "valid_recall :  0.5342205323193916\n",
      "valid_precision :  0.1341288782816229\n",
      "===================LOSS========================\n",
      "loss :  0.0028975678611154417 0.6942793978016313 0.0007798456516873721 0.01015897222974572\n",
      "val_loss :  0.0002994782118022206 nan 8.997159295833662e-05 0.3057670125065335\n",
      "epoch :  8 ,train_loss :  1.072179715448118 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [2:04:16<2:04:14, 745.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.13012715597694346 valid_num :  898\n",
      "valid_recall :  0.7129277566539924\n",
      "valid_precision :  0.15611990008326396\n",
      "===================LOSS========================\n",
      "loss :  0.0028933105076823177 0.6942090615173059 0.0006566636097198492 0.008797190074141353\n",
      "val_loss :  0.0003010709109012647 nan 0.00012828121216840242 0.30909243367213524\n",
      "epoch :  9 ,train_loss :  1.0580036601162153 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [2:16:31<1:51:21, 742.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.0922899824041976 valid_num :  1405\n",
      "valid_recall :  0.8212927756653993\n",
      "valid_precision :  0.1390408754425491\n",
      "===================LOSS========================\n",
      "loss :  0.0028956187340232844 0.694144741767267 0.0006963298517046213 0.010657988763166733\n",
      "val_loss :  0.00029843421324537636 nan 9.573840309856582e-05 0.21993066734005545\n",
      "epoch :  10 ,train_loss :  1.0639975904687051 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [2:28:52<1:38:56, 742.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.13140606854090398 valid_num :  760\n",
      "valid_recall :  0.6045627376425855\n",
      "valid_precision :  0.1515007146260124\n",
      "===================LOSS========================\n",
      "loss :  0.002891180679549183 0.6941157719596519 0.0006239134707939303 0.007130925277684165\n",
      "val_loss :  0.0002998354549354668 nan 0.00011105996114181575 0.25189588693942583\n",
      "epoch :  11 ,train_loss :  1.052756115337091 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [2:41:10<1:26:24, 740.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.13122621672417104 valid_num :  480\n",
      "valid_recall :  0.48098859315589354\n",
      "valid_precision :  0.14988151658767773\n",
      "===================LOSS========================\n",
      "loss :  0.0028805008453976675 0.6941033382357263 0.0005758459994345734 0.00847507777745485\n",
      "val_loss :  0.00029894384105749565 nan 9.641681714576951e-05 0.3583967070951279\n",
      "epoch :  12 ,train_loss :  1.0482131035537563 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [2:53:28<1:13:58, 739.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.11891018647961532 valid_num :  1069\n",
      "valid_recall :  0.7224334600760456\n",
      "valid_precision :  0.149547422274695\n",
      "===================LOSS========================\n",
      "loss :  0.0028831390902942337 0.6940489930609253 0.0005206402767515934 0.005562303203433287\n",
      "val_loss :  0.000299741820055332 nan 9.804112639685806e-05 0.30375134906784007\n",
      "epoch :  13 ,train_loss :  1.0399892324075133 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [3:06:01<1:01:59, 743.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.1780497255930727 valid_num :  491\n",
      "valid_recall :  0.5038022813688213\n",
      "valid_precision :  0.16327788046826863\n",
      "===================LOSS========================\n",
      "loss :  0.002880874860285189 0.6940559308465517 0.00048720897575735305 0.006662459453795932\n",
      "val_loss :  0.0002972784228739712 nan 0.00012795506922959465 0.35041787760598564\n",
      "epoch :  14 ,train_loss :  1.0375267747477277 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [3:18:20<49:29, 742.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.16497948975951593 valid_num :  532\n",
      "valid_recall :  0.5342205323193916\n",
      "valid_precision :  0.15938740782756664\n",
      "===================LOSS========================\n",
      "loss :  0.002892682594087657 0.693967496203011 0.0004107993349453047 0.004242853537362101\n",
      "val_loss :  0.00029966747838204214 nan 0.00013105087512644187 0.3348370882481534\n",
      "epoch :  15 ,train_loss :  1.0285585410512055 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [3:31:00<37:22, 747.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.1901388319624528 valid_num :  393\n",
      "valid_recall :  0.44106463878326996\n",
      "valid_precision :  0.16453900709219857\n",
      "===================LOSS========================\n",
      "loss :  0.0028864560778069943 0.693928326809577 0.00042891421207503984 0.004803207180821546\n",
      "val_loss :  0.00029454295947384945 nan 0.00013673720172040611 0.3973947381827172\n",
      "epoch :  16 ,train_loss :  1.0302685638146898 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [3:43:48<25:07, 753.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.17287682214577305 valid_num :  634\n",
      "valid_recall :  0.6140684410646388\n",
      "valid_precision :  0.1650485436893204\n",
      "===================LOSS========================\n",
      "loss :  0.0028848646891066246 0.6938906058455782 0.0003517764945218563 0.0044779622873028545\n",
      "val_loss :  0.0002984844295832246 nan 0.0001636785890372095 0.3540373016297029\n",
      "epoch :  17 ,train_loss :  1.0220326904382686 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [3:56:05<12:28, 748.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.17808608486683308 valid_num :  422\n",
      "valid_recall :  0.49049429657794674\n",
      "valid_precision :  0.15674362089914945\n",
      "===================LOSS========================\n",
      "loss :  0.0028780959167442493 0.6939147407291857 0.0003630553539903781 0.004320601947159649\n",
      "val_loss :  0.0002958312536257405 nan 0.00016718015739711298 0.3635833885101623\n",
      "epoch :  18 ,train_loss :  1.0223504731503976 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [4:08:22<00:00, 745.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RPN========================\n",
      "rpn_pos_per_batch 7.9079754601226995 489\n",
      "rpn_neg_per_batch 2039.5685071574642 489\n",
      "val_rpn_pos_per_batch 0.9592105263157895 760\n",
      "val_rpn_neg_per_batch 2045.6934210526315 760\n",
      "===================ROI========================\n",
      "valid_iou :  0.23603939132368273 valid_num :  310\n",
      "valid_recall :  0.3916349809885932\n",
      "valid_precision :  0.17195325542570952\n",
      "===================LOSS========================\n",
      "loss :  0.002895982982686022 0.6938687122916395 0.000354015469853366 0.003798156544546633\n",
      "val_loss :  0.00029846280557122603 nan 0.00016984277765771675 0.4438335094337052\n",
      "epoch :  19 ,train_loss :  1.0226667140646701 ,valid_loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(),  lr=0.0001, momentum=0.9)   # optimize all cnn parameters\n",
    "# torch.optim.Adam(model.parameters(), lr=1e-4, betas = (0.9, 0.999), weight_decay=5e-4)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas = (0.9, 0.999), weight_decay=5e-4)\n",
    "optimizer = torch.optim.SGD(model.parameters(),  lr=lr, momentum=0.9, weight_decay=0.0005)   # optimize all cnn parameters\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=1,gamma=0.95)\n",
    "# Freeze_Epoch = 50\n",
    "Unfreeze_Epoch = epoch\n",
    "best_valid_loss_avg = np.inf\n",
    "\n",
    "# Unfreezed training and validating\n",
    "\n",
    "print('start training (unfreeze ResNet50)')\n",
    "\n",
    "for epoch in tqdm(range(Unfreeze_Epoch)):\n",
    "#     total_loss = np.array([])\n",
    "    rpn_loc_loss = []\n",
    "    rpn_cls_loss = []\n",
    "    roi_loc_loss = []\n",
    "    roi_cls_loss = []\n",
    "    val_rpn_loc_loss = []\n",
    "    val_rpn_cls_loss = []\n",
    "    val_roi_loc_loss = []\n",
    "    val_roi_cls_loss = []\n",
    "#     val_toal_loss = np.array([])\n",
    "\n",
    "    trainlosslist = []\n",
    "    validlosslist = []\n",
    "#     loss_weight = [100,1,100,10]\n",
    "    \n",
    "    rpn_pos_per_batch = []\n",
    "    rpn_neg_per_batch = []\n",
    "    val_rpn_pos_per_batch = []\n",
    "    val_rpn_neg_per_batch = []\n",
    "\n",
    "    # train\n",
    "    model.train()\n",
    "    for step, (imgs, bboxes, labels) in enumerate(train_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            bboxes = bboxes.cuda()\n",
    "            labels = labels.cuda()\n",
    "        targets = []\n",
    "        mode = 'train'\n",
    "        for i in range(imgs.shape[0]):\n",
    "            bbox = bboxes[i]\n",
    "            label = labels[i]\n",
    "            try:\n",
    "                label_num = torch.nonzero(label == 0)[0][0]\n",
    "            except:\n",
    "                label_num = label.shape[0]\n",
    "            label = label[:label_num]\n",
    "            bbox = bbox[:label_num]\n",
    "            d = {}\n",
    "            d['boxes'] = bbox\n",
    "            d['labels'] = label\n",
    "            targets.append(d)\n",
    "        output = model(imgs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        losses = output['loss_rpn_box_reg']*100 + output['loss_objectness']*1 + output['loss_box_reg']*100 + output['loss_classifier']*1\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        rpn_loc_loss.append(output['loss_rpn_box_reg'].item())\n",
    "        rpn_cls_loss.append(output['loss_objectness'].item())\n",
    "        roi_loc_loss.append(output['loss_box_reg'].item())\n",
    "        roi_cls_loss.append(output['loss_classifier'].item())\n",
    "        trainlosslist.append(losses.item())\n",
    "\n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, bboxes, labels) in enumerate(valid_dataloader):\n",
    "            if torch.cuda.is_available():\n",
    "                imgs = imgs.cuda()\n",
    "                bboxes = bboxes.cuda()\n",
    "                labels = labels.cuda()\n",
    "            targets = []\n",
    "            mode = 'valid'\n",
    "            for i in range(imgs.shape[0]):\n",
    "                bbox = bboxes[i]\n",
    "                label = labels[i]\n",
    "                try:\n",
    "                    label_num = torch.nonzero(label == 0)[0][0]\n",
    "                except:\n",
    "                    label_num = label.shape[0]\n",
    "                label = label[:label_num]\n",
    "                bbox = bbox[:label_num]\n",
    "                d = {}\n",
    "                d['boxes'] = bbox\n",
    "                d['labels'] = label\n",
    "                targets.append(d)    \n",
    "            output = model(imgs, targets) \n",
    "            losses = output['loss_rpn_box_reg']*100 + output['loss_objectness']*1 + output['loss_box_reg']*100 + output['loss_classifier']*1\n",
    "            val_rpn_loc_loss.append(output['loss_rpn_box_reg'].item())\n",
    "            val_rpn_cls_loss.append(output['loss_objectness'].item())\n",
    "            val_roi_loc_loss.append(output['loss_box_reg'].item())\n",
    "            val_roi_cls_loss.append(output['loss_classifier'].item())\n",
    "            validlosslist.append(losses.item())\n",
    "    # validate iou\n",
    "    model.eval()\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    iou_array = np.array([])\n",
    "    for step, (imgs, bboxes, labels) in enumerate(valid_iou_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            bboxes = bboxes.cuda()\n",
    "            labels = labels.cuda()\n",
    "        bbox, label = 0, 0\n",
    "        mode = 'valid'\n",
    "        for i in range(imgs.shape[0]):\n",
    "            bbox = bboxes[i]\n",
    "            label = labels[i]\n",
    "            try:\n",
    "                label_num = torch.nonzero(label == 0)[0][0]\n",
    "            except:\n",
    "                label_num = label.shape[0]\n",
    "            label = label[:label_num]\n",
    "            bbox = bbox[:label_num]\n",
    "        output = model(imgs)\n",
    "        indices = torch.where(output[0]['scores'] > 0.5)[0]\n",
    "        if indices.shape[0] > 0:\n",
    "            if label.shape[0] > 0:\n",
    "                true_pos += 1\n",
    "                ious = bbox_iou(output[0]['boxes'][indices].cpu().detach().numpy(), bbox.cpu().numpy())\n",
    "                max_ious = np.max(ious, axis=1)\n",
    "                iou_array = np.append(iou_array, max_ious)\n",
    "            else :\n",
    "                false_pos += 1\n",
    "        else :\n",
    "            if label.shape[0] > 0:\n",
    "                false_neg += 1\n",
    "            else :\n",
    "                true_neg += 1\n",
    "\n",
    "    \n",
    "    train_loss_avg = np.mean(trainlosslist)\n",
    "    rpn_loc_loss_avg = np.mean(rpn_loc_loss)\n",
    "    rpn_cls_loss_avg = np.mean(rpn_cls_loss)\n",
    "    roi_loc_loss_avg = np.mean(roi_loc_loss)\n",
    "    roi_cls_loss_avg = np.mean(roi_cls_loss)\n",
    "    valid_loss_avg = np.mean(validlosslist)\n",
    "    val_rpn_loc_loss_avg = np.mean(val_rpn_loc_loss)\n",
    "    val_rpn_cls_loss_avg = np.mean(val_rpn_cls_loss)\n",
    "    val_roi_loc_loss_avg = np.mean(val_roi_loc_loss)\n",
    "    val_roi_cls_loss_avg = np.mean(val_roi_cls_loss)\n",
    "\n",
    "    print('===================RPN========================')\n",
    "    print('rpn_pos_per_batch', np.mean(rpn_pos_per_batch), len(rpn_pos_per_batch))\n",
    "    print('rpn_neg_per_batch', np.mean(rpn_neg_per_batch), len(rpn_neg_per_batch))\n",
    "    print('val_rpn_pos_per_batch', np.mean(val_rpn_pos_per_batch), len(val_rpn_pos_per_batch))\n",
    "    print('val_rpn_neg_per_batch', np.mean(val_rpn_neg_per_batch), len(val_rpn_neg_per_batch))\n",
    "    \n",
    "    print('===================ROI========================')\n",
    "    print('valid_iou : ', np.mean(iou_array), 'valid_num : ', iou_array.size)\n",
    "    try:\n",
    "        print('valid_recall : ', true_pos/(true_pos+false_neg))\n",
    "    except:\n",
    "        print('valid_recall : ', 0)\n",
    "    try:\n",
    "        print('valid_precision : ', true_pos/(true_pos+false_pos))\n",
    "    except:\n",
    "        print('valid_precision : ', 0)\n",
    "    \n",
    "    print('===================LOSS========================')\n",
    "    print('loss : ', rpn_loc_loss_avg, rpn_cls_loss_avg, roi_loc_loss_avg, roi_cls_loss_avg)\n",
    "    print('val_loss : ', val_rpn_loc_loss_avg, val_rpn_cls_loss_avg, val_roi_loc_loss_avg, val_roi_cls_loss_avg)\n",
    "    print('epoch : ', epoch, ',train_loss : ',train_loss_avg, ',valid_loss : ', valid_loss_avg)\n",
    "    # wandb.log({\"EPOCHS\":epoch, \"Train Loss\":train_loss_avg, \"Valid Loss\":valid_loss_avg}) \n",
    "    if valid_loss_avg < best_valid_loss_avg :\n",
    "        best_valid_loss_avg = valid_loss_avg\n",
    "        print('saving model weight') \n",
    "        torch.save(model.state_dict(), '/kaggle/working/weight.pt')\n",
    "    lr_scheduler.step()\n",
    "# wandb.finish() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4b825",
   "metadata": {
    "papermill": {
     "duration": 0.030233,
     "end_time": "2023-06-03T22:13:36.600171",
     "exception": false,
     "start_time": "2023-06-03T22:13:36.569938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 拜託好運貓貓讓我 train 成功 \n",
    "![](https://hips.hearstapps.com/hmg-prod/images/beautiful-smooth-haired-red-cat-lies-on-the-sofa-royalty-free-image-1678488026.jpg?crop=1.00xw:0.752xh;0,0.0457xh&resize=640:*)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14969.500447,
   "end_time": "2023-06-03T22:13:39.789540",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-03T18:04:10.289093",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
